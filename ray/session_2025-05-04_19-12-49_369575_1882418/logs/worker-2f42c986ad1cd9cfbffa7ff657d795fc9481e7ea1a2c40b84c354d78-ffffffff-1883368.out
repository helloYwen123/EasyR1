:job_id:01000000
INFO 05-04 19:13:02 [__init__.py:239] Automatically detected platform cuda.
:actor_name:Runner
{
  "data": {
    "train_files": "BLINK-Benchmark/BLINK",
    "val_files": "BLINK-Benchmark/BLINK",
    "prompt_key": "problem",
    "answer_key": "answer",
    "image_key": "images",
    "max_prompt_length": 2048,
    "max_response_length": 2048,
    "rollout_batch_size": 8,
    "val_batch_size": -1,
    "format_prompt": "/home/stud/wxie/EasyR1/examples/format_prompt/tools_thinker_format.jinja",
    "override_chat_template": null,
    "shuffle": true,
    "seed": 1,
    "max_pixels": 4194304,
    "min_pixels": 262144,
    "filter_overlong_prompts": false,
    "subtasks": [
      "Counting"
    ],
    "dataset_prefix": "/home/stud/wxie",
    "tools_config": "./examples/tools_config/tools_configuration_file.yaml"
  },
  "worker": {
    "hybrid_engine": true,
    "actor": {
      "strategy": "fsdp",
      "global_batch_size": 4,
      "micro_batch_size_per_device_for_update": 2,
      "micro_batch_size_per_device_for_experience": 4,
      "max_grad_norm": 1.0,
      "clip_ratio_low": 0.2,
      "clip_ratio_high": 0.3,
      "clip_ratio_dual": 3.0,
      "ppo_epochs": 1,
      "padding_free": true,
      "ulysses_sequence_parallel_size": 1,
      "use_torch_compile": true,
      "model": {
        "model_path": "Qwen/Qwen2.5-VL-3B-Instruct",
        "tokenizer_path": "Qwen/Qwen2.5-VL-3B-Instruct",
        "override_config": {},
        "enable_gradient_checkpointing": true,
        "trust_remote_code": false,
        "freeze_vision_tower": false
      },
      "optim": {
        "lr": 1e-06,
        "betas": [
          0.9,
          0.999
        ],
        "weight_decay": 0.01,
        "strategy": "adamw_bf16",
        "lr_warmup_ratio": 0.0,
        "min_lr_ratio": null,
        "warmup_style": "constant",
        "training_steps": -1
      },
      "fsdp": {
        "enable_full_shard": true,
        "enable_cpu_offload": false,
        "enable_rank0_init": true,
        "use_orig_params": false,
        "torch_dtype": "bf16",
        "fsdp_size": -1,
        "mp_param_dtype": "bf16",
        "mp_reduce_dtype": "fp32",
        "mp_buffer_dtype": "fp32"
      },
      "offload": {
        "offload_params": true,
        "offload_optimizer": true
      },
      "global_batch_size_per_device": -1,
      "disable_kl": false,
      "use_kl_loss": true,
      "kl_penalty": "low_var_kl",
      "kl_coef": 0.01
    },
    "critic": {
      "strategy": "fsdp",
      "global_batch_size": 256,
      "micro_batch_size_per_device_for_update": 4,
      "micro_batch_size_per_device_for_experience": 16,
      "max_grad_norm": 1.0,
      "cliprange_value": 0.5,
      "ppo_epochs": 1,
      "padding_free": false,
      "ulysses_sequence_parallel_size": 1,
      "model": {
        "model_path": null,
        "tokenizer_path": null,
        "override_config": {},
        "enable_gradient_checkpointing": true,
        "trust_remote_code": true,
        "freeze_vision_tower": false
      },
      "optim": {
        "lr": 1e-06,
        "betas": [
          0.9,
          0.999
        ],
        "weight_decay": 0.01,
        "strategy": "adamw",
        "lr_warmup_ratio": 0.0,
        "min_lr_ratio": null,
        "warmup_style": "constant",
        "training_steps": -1
      },
      "fsdp": {
        "enable_full_shard": true,
        "enable_cpu_offload": false,
        "enable_rank0_init": false,
        "use_orig_params": false,
        "torch_dtype": null,
        "fsdp_size": -1,
        "mp_param_dtype": "bf16",
        "mp_reduce_dtype": "fp32",
        "mp_buffer_dtype": "fp32"
      },
      "offload": {
        "offload_params": false,
        "offload_optimizer": false
      },
      "global_batch_size_per_device": -1
    },
    "ref": {
      "strategy": "fsdp",
      "fsdp": {
        "enable_full_shard": true,
        "enable_cpu_offload": true,
        "enable_rank0_init": true,
        "use_orig_params": false,
        "torch_dtype": "bf16",
        "fsdp_size": -1,
        "mp_param_dtype": "bf16",
        "mp_reduce_dtype": "fp32",
        "mp_buffer_dtype": "fp32"
      },
      "offload": {
        "offload_params": false,
        "offload_optimizer": false
      },
      "micro_batch_size_per_device_for_experience": 4,
      "padding_free": true,
      "ulysses_sequence_parallel_size": 1,
      "use_torch_compile": true
    },
    "reward": {
      "reward_type": "batch",
      "reward_function": "/home/stud/wxie/EasyR1/examples/reward_function/tool_reward.py",
      "reward_function_kwargs": {
        "format_weight": 0.3,
        "usage_weight": 0.5,
        "execution_weight": 0.2
      },
      "skip_special_tokens": true,
      "num_cpus": 1,
      "num_gpus": 0,
      "reward_function_name": "compute_score"
    },
    "rollout": {
      "name": "vllm",
      "n": 6,
      "temperature": 1.0,
      "top_p": 0.99,
      "top_k": -1,
      "seed": 1,
      "limit_images": 0,
      "dtype": "bf16",
      "gpu_memory_utilization": 0.6,
      "ignore_eos": false,
      "enforce_eager": false,
      "enable_chunked_prefill": false,
      "tensor_parallel_size": 1,
      "max_model_len": null,
      "max_num_batched_tokens": 8192,
      "disable_log_stats": true,
      "val_override_config": {
        "temperature": 0.5,
        "n": 1
      },
      "prompt_length": 2048,
      "response_length": 2048,
      "trust_remote_code": false
    }
  },
  "algorithm": {
    "gamma": 1.0,
    "lam": 1.0,
    "adv_estimator": "grpo",
    "disable_kl": false,
    "use_kl_loss": true,
    "kl_penalty": "low_var_kl",
    "kl_coef": 0.01,
    "kl_type": "fixed",
    "kl_horizon": 0.0,
    "kl_target": 0.0
  },
  "trainer": {
    "total_epochs": 1,
    "max_steps": null,
    "project_name": "Debug",
    "experiment_name": "qwen2_5_vl_3b_grpo",
    "logger": [
      "console",
      "wandb"
    ],
    "nnodes": 1,
    "n_gpus_per_node": 1,
    "critic_warmup": 0,
    "val_freq": -1,
    "val_before_train": false,
    "val_only": false,
    "val_generations_to_log": 3,
    "save_freq": -1,
    "save_limit": 3,
    "save_checkpoint_path": "/home/stud/wxie/EasyR1/checkpoints/Debug/qwen2_5_vl_3b_grpo",
    "load_checkpoint_path": null
  }
}
loading dataset: BLINK-Benchmark/BLINK

loading dataset: BLINK-Benchmark/BLINK

Size of train dataloader: 15
Size of val dataloader: 1
Tool usage reward: True
Total training steps: 15
Config
algorithm:
  adv_estimator: grpo
  disable_kl: false
  gamma: 1.0
  kl_coef: 0.01
  kl_horizon: 0.0
  kl_penalty: low_var_kl
  kl_target: 0.0
  kl_type: fixed
  lam: 1.0
  use_kl_loss: true
data:
  answer_key: answer
  dataset_prefix: /home/stud/wxie
  filter_overlong_prompts: false
  format_prompt: /home/stud/wxie/EasyR1/examples/format_prompt/tools_thinker_format.jinja
  image_key: images
  max_pixels: 4194304
  max_prompt_length: 2048
  max_response_length: 2048
  min_pixels: 262144
  override_chat_template: null
  prompt_key: problem
  rollout_batch_size: 8
  seed: 1
  shuffle: true
  subtasks:
  - Counting
  tools_config: ./examples/tools_config/tools_configuration_file.yaml
  train_files: BLINK-Benchmark/BLINK
  val_batch_size: -1
  val_files: BLINK-Benchmark/BLINK
trainer:
  critic_warmup: 0
  experiment_name: qwen2_5_vl_3b_grpo
  load_checkpoint_path: null
  logger:
  - console
  - wandb
  max_steps: null
  n_gpus_per_node: 1
  nnodes: 1
  project_name: Debug
  save_checkpoint_path: /home/stud/wxie/EasyR1/checkpoints/Debug/qwen2_5_vl_3b_grpo
  save_freq: -1
  save_limit: 3
  total_epochs: 1
  val_before_train: false
  val_freq: -1
  val_generations_to_log: 3
  val_only: false
worker:
  actor:
    clip_ratio_dual: 3.0
    clip_ratio_high: 0.3
    clip_ratio_low: 0.2
    disable_kl: false
    fsdp:
      enable_cpu_offload: false
      enable_full_shard: true
      enable_rank0_init: true
      fsdp_size: -1
      mp_buffer_dtype: fp32
      mp_param_dtype: bf16
      mp_reduce_dtype: fp32
      torch_dtype: bf16
      use_orig_params: false
    global_batch_size: 4
    global_batch_size_per_device: -1
    kl_coef: 0.01
    kl_penalty: low_var_kl
    max_grad_norm: 1.0
    micro_batch_size_per_device_for_experience: 4
    micro_batch_size_per_device_for_update: 2
    model:
      enable_gradient_checkpointing: true
      freeze_vision_tower: false
      model_path: Qwen/Qwen2.5-VL-3B-Instruct
      override_config: {}
      tokenizer_path: Qwen/Qwen2.5-VL-3B-Instruct
      trust_remote_code: false
    offload:
      offload_optimizer: true
      offload_params: true
    optim:
      betas:
      - 0.9
      - 0.999
      lr: 1.0e-06
      lr_warmup_ratio: 0.0
      min_lr_ratio: null
      strategy: adamw_bf16
      training_steps: 15
      warmup_style: constant
      weight_decay: 0.01
    padding_free: true
    ppo_epochs: 1
    strategy: fsdp
    ulysses_sequence_parallel_size: 1
    use_kl_loss: true
    use_torch_compile: true
  critic:
    cliprange_value: 0.5
    fsdp:
      enable_cpu_offload: false
      enable_full_shard: true
      enable_rank0_init: false
      fsdp_size: -1
      mp_buffer_dtype: fp32
      mp_param_dtype: bf16
      mp_reduce_dtype: fp32
      torch_dtype: null
      use_orig_params: false
    global_batch_size: 256
    global_batch_size_per_device: -1
    max_grad_norm: 1.0
    micro_batch_size_per_device_for_experience: 16
    micro_batch_size_per_device_for_update: 4
    model:
      enable_gradient_checkpointing: true
      freeze_vision_tower: false
      model_path: null
      override_config: {}
      tokenizer_path: null
      trust_remote_code: true
    offload:
      offload_optimizer: false
      offload_params: false
    optim:
      betas:
      - 0.9
      - 0.999
      lr: 1.0e-06
      lr_warmup_ratio: 0.0
      min_lr_ratio: null
      strategy: adamw
      training_steps: 15
      warmup_style: constant
      weight_decay: 0.01
    padding_free: false
    ppo_epochs: 1
    strategy: fsdp
    ulysses_sequence_parallel_size: 1
  hybrid_engine: true
  ref:
    fsdp:
      enable_cpu_offload: true
      enable_full_shard: true
      enable_rank0_init: true
      fsdp_size: -1
      mp_buffer_dtype: fp32
      mp_param_dtype: bf16
      mp_reduce_dtype: fp32
      torch_dtype: bf16
      use_orig_params: false
    micro_batch_size_per_device_for_experience: 4
    offload:
      offload_optimizer: false
      offload_params: false
    padding_free: true
    strategy: fsdp
    ulysses_sequence_parallel_size: 1
    use_torch_compile: true
  reward:
    num_cpus: 1
    num_gpus: 0
    reward_function: /home/stud/wxie/EasyR1/examples/reward_function/tool_reward.py
    reward_function_kwargs:
      execution_weight: 0.2
      format_weight: 0.3
      usage_weight: 0.5
    reward_function_name: compute_score
    reward_type: batch
    skip_special_tokens: true
  rollout:
    disable_log_stats: true
    dtype: bf16
    enable_chunked_prefill: false
    enforce_eager: false
    gpu_memory_utilization: 0.6
    ignore_eos: false
    limit_images: 0
    max_model_len: null
    max_num_batched_tokens: 8192
    n: 6
    name: vllm
    prompt_length: 2048
    response_length: 2048
    seed: 1
    temperature: 1.0
    tensor_parallel_size: 1
    top_k: -1
    top_p: 0.99
    trust_remote_code: false
    val_override_config:
      n: 1
      temperature: 0.5

{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 0, "desc": "Epoch", "total": 1, "unit": "it", "ip": "10.153.51.195", "pid": 1883368, "uuid": "c2443e2ad7084142b289d03e6f5c9343", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 1, "desc": "Running step", "total": 15, "unit": "it", "ip": "10.153.51.195", "pid": 1883368, "uuid": "a36ac7eb99a7440c9ea384ef8547f14d", "closed": false}
global_step in reward computation: 1
Step 1
actor:
  entropy_loss: 0.456
  grad_norm: 4.547
  kl_coef: 0.01
  kl_loss: 0.001
  lr: 1.0e-06
  pg_clipfrac_higher: 0.001
  pg_clipfrac_lower: 0.0
  pg_loss: 0.056
  ppo_kl: 0.0
critic:
  advantages:
    max: 1.04
    mean: -0.436
    min: -1.967
  returns:
    max: 1.04
    mean: -0.436
    min: -1.967
  rewards:
    max: 0.8
    mean: 0.529
    min: 0.0
  score:
    max: 0.8
    mean: 0.529
    min: 0.0
global_seqlen:
  balanced_max: 89256
  balanced_min: 89256
  max: 89256
  mean: 89256.0
  min: 89256
  minmax_diff: 0
perf:
  cpu_memory_used_gb: 34.163
  max_memory_allocated_gb: 46.584
  max_memory_reserved_gb: 55.033
  mfu_actor: 0.086
  throughput: 924.377
  time_per_step: 96.558
  total_num_tokens: 89256
prompt_length:
  clip_ratio: 0.0
  max: 1693.0
  mean: 1682.0
  min: 1674.0
response_length:
  clip_ratio: 0.021
  max: 2048.0
  mean: 177.5
  min: 22.0
reward:
  execution: 0.021
  format: 0.5
  overall: 0.529
  tool_usage: 0.75
timing_per_token_ms:
  adv: 3.6360792454408576e-05
  gen: 2.183
  old: 0.047
  ref: 0.302
  reward: 0.022
  update_actor: 0.522
timing_s:
  adv: 0.003
  gen: 18.602
  old: 4.162
  ref: 26.967
  reward: 0.183
  step: 96.558
  update_actor: 46.614

{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 1, "desc": "Running step", "total": 15, "unit": "it", "ip": "10.153.51.195", "pid": 1883368, "uuid": "a36ac7eb99a7440c9ea384ef8547f14d", "closed": false}
