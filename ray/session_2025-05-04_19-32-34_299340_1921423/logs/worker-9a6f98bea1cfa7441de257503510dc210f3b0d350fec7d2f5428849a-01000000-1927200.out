:job_id:01000000
INFO 05-04 19:33:06 [__init__.py:239] Automatically detected platform cuda.
:actor_name:WorkerDict
actor will use global batch size 10.
Model config: Qwen2_5_VLConfig {
  "architectures": [
    "Qwen2_5_VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 128000,
  "max_window_layers": 70,
  "model_type": "qwen2_5_vl",
  "num_attention_heads": 16,
  "num_hidden_layers": 36,
  "num_key_value_heads": 2,
  "pad_token_id": 151643,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.51.3",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "fullatt_block_indexes": [
      7,
      15,
      23,
      31
    ],
    "hidden_act": "silu",
    "hidden_size": 1280,
    "in_channels": 3,
    "in_chans": 3,
    "intermediate_size": 3420,
    "model_type": "qwen2_5_vl",
    "num_heads": 16,
    "out_hidden_size": 2048,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "tokens_per_second": 2,
    "window_size": 112
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

Ulysses patch applied!
NCCL version 2.21.5+cuda12.4
Qwen2_5_VLForConditionalGeneration contains 3.75B parameters.
After huggingface model init: 1.48 GB / 93.02 GB.
FSDP wrap policy: functools.partial(<function transformer_auto_wrap_policy at 0x7c4437ff6de0>, transformer_layer_cls={<class 'transformers.models.qwen2_5_vl.modeling_qwen2_5_vl.Qwen2_5_VLDecoderLayer'>, <class 'transformers.models.qwen2_5_vl.modeling_qwen2_5_vl.Qwen2_5_VLVisionBlock'>}).
After FSDP module init: 9.34 GB / 93.02 GB.
Model config: Qwen2_5_VLConfig {
  "architectures": [
    "Qwen2_5_VLForConditionalGeneration"
  ],
  "attention_dropout": 0.0,
  "eos_token_id": 151645,
  "hidden_act": "silu",
  "hidden_size": 2048,
  "image_token_id": 151655,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 128000,
  "max_window_layers": 70,
  "model_type": "qwen2_5_vl",
  "num_attention_heads": 16,
  "num_hidden_layers": 36,
  "num_key_value_heads": 2,
  "pad_token_id": 151643,
  "rms_norm_eps": 1e-06,
  "rope_scaling": {
    "mrope_section": [
      16,
      24,
      24
    ],
    "rope_type": "default",
    "type": "default"
  },
  "rope_theta": 1000000.0,
  "sliding_window": 32768,
  "tie_word_embeddings": true,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.51.3",
  "use_cache": true,
  "use_sliding_window": false,
  "video_token_id": 151656,
  "vision_config": {
    "depth": 32,
    "fullatt_block_indexes": [
      7,
      15,
      23,
      31
    ],
    "hidden_act": "silu",
    "hidden_size": 1280,
    "in_channels": 3,
    "in_chans": 3,
    "intermediate_size": 3420,
    "model_type": "qwen2_5_vl",
    "num_heads": 16,
    "out_hidden_size": 2048,
    "patch_size": 14,
    "spatial_merge_size": 2,
    "spatial_patch_size": 14,
    "temporal_patch_size": 2,
    "tokens_per_second": 2,
    "window_size": 112
  },
  "vision_end_token_id": 151653,
  "vision_start_token_id": 151652,
  "vision_token_id": 151654,
  "vocab_size": 151936
}

Ulysses patch applied!
Qwen2_5_VLForConditionalGeneration contains 3.75B parameters.
After huggingface model init: 9.34 GB / 93.02 GB.
FSDP wrap policy: functools.partial(<function transformer_auto_wrap_policy at 0x7c4437ff6de0>, transformer_layer_cls={<class 'transformers.models.qwen2_5_vl.modeling_qwen2_5_vl.Qwen2_5_VLDecoderLayer'>, <class 'transformers.models.qwen2_5_vl.modeling_qwen2_5_vl.Qwen2_5_VLVisionBlock'>}).
After FSDP module init: 16.44 GB / 93.02 GB.
After optimizer init: 16.44 GB / 93.02 GB.
After offload actor model during init: 15.64 GB / 93.02 GB.
After offload actor optimizer during init: 15.64 GB / 93.02 GB.
INFO 05-04 19:34:40 [config.py:689] This model supports multiple tasks: {'embed', 'reward', 'generate', 'score', 'classify'}. Defaulting to 'generate'.
INFO 05-04 19:34:40 [config.py:1672] Disabling V1 multiprocessing for external launcher.
INFO 05-04 19:34:40 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 05-04 19:34:41 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='Qwen/Qwen2.5-VL-3B-Instruct', speculative_config=None, tokenizer='Qwen/Qwen2.5-VL-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.DUMMY, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=1, served_model_name=Qwen/Qwen2.5-VL-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=True, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 05-04 19:34:42 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7c438a455cd0>
INFO 05-04 19:34:42 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 05-04 19:34:42 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 05-04 19:34:49 [gpu_model_runner.py:1276] Starting to load model Qwen/Qwen2.5-VL-3B-Instruct...
INFO 05-04 19:34:49 [config.py:3466] cudagraph sizes specified by model runner [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256, 264, 272, 280, 288, 296, 304, 312, 320, 328, 336, 344, 352, 360, 368, 376, 384, 392, 400, 408, 416, 424, 432, 440, 448, 456, 464, 472, 480, 488, 496, 504, 512] is overridden by config [512, 384, 256, 128, 4, 2, 1, 392, 264, 136, 8, 400, 272, 144, 16, 408, 280, 152, 24, 416, 288, 160, 32, 424, 296, 168, 40, 432, 304, 176, 48, 440, 312, 184, 56, 448, 320, 192, 64, 456, 328, 200, 72, 464, 336, 208, 80, 472, 344, 216, 88, 120, 480, 352, 248, 224, 96, 488, 504, 360, 232, 104, 496, 368, 240, 112, 376]
INFO 05-04 19:34:49 [topk_topp_sampler.py:44] Currently, FlashInfer top-p & top-k sampling sampler is disabled because FlashInfer>=v0.2.3 is not backward compatible. Falling back to the PyTorch-native implementation of top-p & top-k sampling.
INFO 05-04 19:34:49 [gpu_model_runner.py:1291] Model loading took 7.1557 GiB and 0.204172 seconds
INFO 05-04 19:34:52 [gpu_model_runner.py:1560] Encoder cache will be initialized with a budget of 16384 tokens, and profiled with 1 image items of the maximum feature size.
INFO 05-04 19:35:09 [backends.py:416] Using cache directory: /home/wiss/liao/.cache/vllm/torch_compile_cache/5aff8ccb97/rank_0_0 for vLLM's torch.compile
INFO 05-04 19:35:09 [backends.py:426] Dynamo bytecode transform time: 9.78 s
INFO 05-04 19:35:09 [backends.py:115] Directly load the compiled graph for shape None from the cache
INFO 05-04 19:35:18 [monitor.py:33] torch.compile takes 9.78 s in total
INFO 05-04 19:35:19 [kv_cache_utils.py:634] GPU KV cache size: 520,128 tokens
INFO 05-04 19:35:19 [kv_cache_utils.py:637] Maximum concurrency for 4,096 tokens per request: 126.98x
INFO 05-04 19:35:41 [gpu_model_runner.py:1626] Graph capturing finished in 22 secs, took 1.99 GiB
INFO 05-04 19:35:41 [core.py:163] init engine (profile, create kv cache, warmup model) took 51.86 seconds
INFO 05-04 19:35:44 [block_pool.py:264] Successfully reset prefix cache
INFO 05-04 19:35:48 [gpu_worker.py:81] Sleep mode freed 30.37 GiB memory, 17.49 GiB memory is still in use.
INFO 05-04 19:35:48 [executor_base.py:210] It took 4.224012 seconds to fall asleep.
Sampling params: {'max_tokens': 2048, 'detokenize': False, 'logit_bias': {151655: -100}, 'n': 5, 'temperature': 1.0, 'top_p': 0.99, 'top_k': -1, 'seed': 1, 'ignore_eos': False}.
After vllm init: 17.49 GB / 93.02 GB.
Before state_dict() in sharding manager: 24.20 GB / 93.02 GB.
After state_dict() in sharding manager: 24.85 GB / 93.02 GB.
INFO 05-04 19:35:54 [executor_base.py:226] It took 0.152698 seconds to wake up tags ['weights'].
After sync model weights in sharding manager: 32.16 GB / 93.02 GB.
INFO 05-04 19:35:54 [executor_base.py:226] It took 0.002484 seconds to wake up tags ['kv_cache'].
After del state_dict and empty_cache in sharding manager: 42.27 GB / 93.02 GB.
Before vllm offload in sharding manager: 43.05 GB / 93.02 GB.
INFO 05-04 19:36:02 [block_pool.py:264] Successfully reset prefix cache
INFO 05-04 19:36:03 [gpu_worker.py:81] Sleep mode freed 25.88 GiB memory, 17.18 GiB memory is still in use.
INFO 05-04 19:36:03 [executor_base.py:210] It took 0.766789 seconds to fall asleep.
After vllm offload in sharding manager: 17.18 GB / 93.02 GB.
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "d59841f5d6454dd78496526315f16f62", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 4, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "d59841f5d6454dd78496526315f16f62", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "4eba63b846bd4ef883e278283c24ae30", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "4eba63b846bd4ef883e278283c24ae30", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "4e4a75ff6e8f4212a5a35b47aabf38bd", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "01a5a34d9d794f69b8925ece10842198", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "01a5a34d9d794f69b8925ece10842198", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 4, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "01a5a34d9d794f69b8925ece10842198", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "4e4a75ff6e8f4212a5a35b47aabf38bd", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "524253139d2f4776a0b1834dc8ff9362", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "524253139d2f4776a0b1834dc8ff9362", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "524253139d2f4776a0b1834dc8ff9362", "closed": false}
Before state_dict() in sharding manager: 24.95 GB / 93.02 GB.
After state_dict() in sharding manager: 25.60 GB / 93.02 GB.
INFO 05-04 19:36:53 [executor_base.py:226] It took 0.162768 seconds to wake up tags ['weights'].
After sync model weights in sharding manager: 32.91 GB / 93.02 GB.
INFO 05-04 19:36:53 [executor_base.py:226] It took 0.003821 seconds to wake up tags ['kv_cache'].
After del state_dict and empty_cache in sharding manager: 43.11 GB / 93.02 GB.
Before vllm offload in sharding manager: 43.72 GB / 93.02 GB.
INFO 05-04 19:36:57 [block_pool.py:264] Successfully reset prefix cache
INFO 05-04 19:36:58 [gpu_worker.py:81] Sleep mode freed 25.78 GiB memory, 17.94 GiB memory is still in use.
INFO 05-04 19:36:58 [executor_base.py:210] It took 1.046831 seconds to fall asleep.
After vllm offload in sharding manager: 17.94 GB / 93.02 GB.
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "146830db13ea436b9f53d44ce2309314", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "146830db13ea436b9f53d44ce2309314", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "f31b63366ac44266babb1fbda014c743", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "f31b63366ac44266babb1fbda014c743", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "8074ec352757432199aeb9b12ad433e9", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "e2e74af4a2e545d6ba022716f84977b9", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "e2e74af4a2e545d6ba022716f84977b9", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "e2e74af4a2e545d6ba022716f84977b9", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "e2e74af4a2e545d6ba022716f84977b9", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "8074ec352757432199aeb9b12ad433e9", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "f0da4b79840c48c582ba745ea6366319", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "f0da4b79840c48c582ba745ea6366319", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "f0da4b79840c48c582ba745ea6366319", "closed": false}
Before state_dict() in sharding manager: 24.80 GB / 93.02 GB.
After state_dict() in sharding manager: 25.45 GB / 93.02 GB.
INFO 05-04 19:37:13 [executor_base.py:226] It took 0.153695 seconds to wake up tags ['weights'].
After sync model weights in sharding manager: 32.76 GB / 93.02 GB.
INFO 05-04 19:37:13 [executor_base.py:226] It took 0.002769 seconds to wake up tags ['kv_cache'].
After del state_dict and empty_cache in sharding manager: 49.37 GB / 93.02 GB.
Before vllm offload in sharding manager: 49.38 GB / 93.02 GB.
INFO 05-04 19:37:16 [block_pool.py:264] Successfully reset prefix cache
INFO 05-04 19:37:17 [gpu_worker.py:81] Sleep mode freed 25.17 GiB memory, 24.21 GiB memory is still in use.
INFO 05-04 19:37:17 [executor_base.py:210] It took 0.847575 seconds to fall asleep.
After vllm offload in sharding manager: 24.21 GB / 93.02 GB.
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "07dc758a58e745cfa0391dd68a8d4157", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "07dc758a58e745cfa0391dd68a8d4157", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "21d7c4506a574329868e752a0178d87c", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "21d7c4506a574329868e752a0178d87c", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "d3734af1135a4972ab208ba8e2502ea6", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "6a673f12570d4bc1964eed9d5feafd9b", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "6a673f12570d4bc1964eed9d5feafd9b", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 4, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "6a673f12570d4bc1964eed9d5feafd9b", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "d3734af1135a4972ab208ba8e2502ea6", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "052e49dadccd410f9304e6213701b765", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "052e49dadccd410f9304e6213701b765", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "052e49dadccd410f9304e6213701b765", "closed": false}
Before state_dict() in sharding manager: 24.68 GB / 93.02 GB.
After state_dict() in sharding manager: 25.33 GB / 93.02 GB.
INFO 05-04 19:37:31 [executor_base.py:226] It took 0.152171 seconds to wake up tags ['weights'].
After sync model weights in sharding manager: 32.64 GB / 93.02 GB.
INFO 05-04 19:37:31 [executor_base.py:226] It took 0.002631 seconds to wake up tags ['kv_cache'].
After del state_dict and empty_cache in sharding manager: 47.23 GB / 93.02 GB.
Before vllm offload in sharding manager: 47.23 GB / 93.02 GB.
INFO 05-04 19:37:34 [block_pool.py:264] Successfully reset prefix cache
INFO 05-04 19:37:35 [gpu_worker.py:81] Sleep mode freed 25.17 GiB memory, 22.06 GiB memory is still in use.
INFO 05-04 19:37:35 [executor_base.py:210] It took 0.896578 seconds to fall asleep.
After vllm offload in sharding manager: 22.06 GB / 93.02 GB.
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "ee5fe03505364ebd99ab7379e82e7523", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "ee5fe03505364ebd99ab7379e82e7523", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "5db7f15651834624a3c39fa0bba37e86", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "5db7f15651834624a3c39fa0bba37e86", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "b42f9d1e682540d0a2d6beba2e48380b", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "bd469547f29e4d4ca24984e5d10930c2", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "bd469547f29e4d4ca24984e5d10930c2", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 4, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "bd469547f29e4d4ca24984e5d10930c2", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "b42f9d1e682540d0a2d6beba2e48380b", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "946eac622422421898ce6d592f66eae0", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "946eac622422421898ce6d592f66eae0", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "946eac622422421898ce6d592f66eae0", "closed": false}
Before state_dict() in sharding manager: 25.13 GB / 93.02 GB.
After state_dict() in sharding manager: 25.78 GB / 93.02 GB.
INFO 05-04 19:37:51 [executor_base.py:226] It took 0.152597 seconds to wake up tags ['weights'].
After sync model weights in sharding manager: 33.09 GB / 93.02 GB.
INFO 05-04 19:37:51 [executor_base.py:226] It took 0.002493 seconds to wake up tags ['kv_cache'].
After del state_dict and empty_cache in sharding manager: 49.58 GB / 93.02 GB.
Before vllm offload in sharding manager: 49.58 GB / 93.02 GB.
INFO 05-04 19:37:55 [block_pool.py:264] Successfully reset prefix cache
INFO 05-04 19:37:55 [gpu_worker.py:81] Sleep mode freed 25.17 GiB memory, 24.41 GiB memory is still in use.
INFO 05-04 19:37:55 [executor_base.py:210] It took 0.610028 seconds to fall asleep.
After vllm offload in sharding manager: 24.41 GB / 93.02 GB.
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "477adb6f606846c1a0bbfe560103f7af", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "02275124b7674bd1a778f2d940d3bb7a", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "02275124b7674bd1a778f2d940d3bb7a", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "e92b01049d1d49d3837681c415ce8300", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "620b00bdcd6348fca9ba2a9491461405", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "620b00bdcd6348fca9ba2a9491461405", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "620b00bdcd6348fca9ba2a9491461405", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "e92b01049d1d49d3837681c415ce8300", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "9503bb26947f453c8bcdadddfe5b73b5", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "9503bb26947f453c8bcdadddfe5b73b5", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "9503bb26947f453c8bcdadddfe5b73b5", "closed": false}
Before state_dict() in sharding manager: 26.04 GB / 93.02 GB.
After state_dict() in sharding manager: 26.11 GB / 93.02 GB.
INFO 05-04 19:38:09 [executor_base.py:226] It took 0.165795 seconds to wake up tags ['weights'].
After sync model weights in sharding manager: 33.42 GB / 93.02 GB.
INFO 05-04 19:38:09 [executor_base.py:226] It took 0.002459 seconds to wake up tags ['kv_cache'].
After del state_dict and empty_cache in sharding manager: 51.21 GB / 93.02 GB.
Before vllm offload in sharding manager: 51.21 GB / 93.02 GB.
INFO 05-04 19:38:12 [block_pool.py:264] Successfully reset prefix cache
INFO 05-04 19:38:12 [gpu_worker.py:81] Sleep mode freed 25.17 GiB memory, 26.05 GiB memory is still in use.
INFO 05-04 19:38:12 [executor_base.py:210] It took 0.591180 seconds to fall asleep.
After vllm offload in sharding manager: 26.05 GB / 93.02 GB.
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "6beacae9202c457789c8a661bea6e695", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "4d38f958a9f94d6e81aa4646f7e30aea", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "4d38f958a9f94d6e81aa4646f7e30aea", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "5f541ddc38434d21b54ca61f0fb7381f", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "26664f6dc44344d28483cbfb32469458", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "26664f6dc44344d28483cbfb32469458", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "26664f6dc44344d28483cbfb32469458", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "5f541ddc38434d21b54ca61f0fb7381f", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "916dfda4f18444019be96a7bad92650b", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "916dfda4f18444019be96a7bad92650b", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 4, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "916dfda4f18444019be96a7bad92650b", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "916dfda4f18444019be96a7bad92650b", "closed": false}
Before state_dict() in sharding manager: 25.86 GB / 93.02 GB.
After state_dict() in sharding manager: 25.93 GB / 93.02 GB.
INFO 05-04 19:38:28 [executor_base.py:226] It took 0.152000 seconds to wake up tags ['weights'].
After sync model weights in sharding manager: 33.24 GB / 93.02 GB.
INFO 05-04 19:38:28 [executor_base.py:226] It took 0.002335 seconds to wake up tags ['kv_cache'].
After del state_dict and empty_cache in sharding manager: 51.03 GB / 93.02 GB.
Before vllm offload in sharding manager: 51.03 GB / 93.02 GB.
INFO 05-04 19:38:32 [block_pool.py:264] Successfully reset prefix cache
INFO 05-04 19:38:32 [gpu_worker.py:81] Sleep mode freed 25.17 GiB memory, 25.86 GiB memory is still in use.
INFO 05-04 19:38:32 [executor_base.py:210] It took 0.587531 seconds to fall asleep.
After vllm offload in sharding manager: 25.86 GB / 93.02 GB.
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "c1e312b69bad4a4a89edfd7c75f2d3fe", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "c9322906122f49c3963b062d1d8500ee", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "c9322906122f49c3963b062d1d8500ee", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "d3457280eda047758c624cdf89750262", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "87eb17d86ac747608af8ce72aae36fb3", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "87eb17d86ac747608af8ce72aae36fb3", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "87eb17d86ac747608af8ce72aae36fb3", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "d3457280eda047758c624cdf89750262", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "e1def25ec470446a817ecc59bc00399f", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "e1def25ec470446a817ecc59bc00399f", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "e1def25ec470446a817ecc59bc00399f", "closed": false}
Before state_dict() in sharding manager: 25.68 GB / 93.02 GB.
After state_dict() in sharding manager: 25.75 GB / 93.02 GB.
INFO 05-04 19:38:45 [executor_base.py:226] It took 0.239113 seconds to wake up tags ['weights'].
After sync model weights in sharding manager: 33.06 GB / 93.02 GB.
INFO 05-04 19:38:45 [executor_base.py:226] It took 0.002354 seconds to wake up tags ['kv_cache'].
After del state_dict and empty_cache in sharding manager: 50.85 GB / 93.02 GB.
Before vllm offload in sharding manager: 50.85 GB / 93.02 GB.
INFO 05-04 19:38:47 [block_pool.py:264] Successfully reset prefix cache
INFO 05-04 19:38:47 [gpu_worker.py:81] Sleep mode freed 25.17 GiB memory, 25.68 GiB memory is still in use.
INFO 05-04 19:38:47 [executor_base.py:210] It took 0.572963 seconds to fall asleep.
After vllm offload in sharding manager: 25.68 GB / 93.02 GB.
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "0170d2381ef548c88ee98ebea0d4a1bc", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "8f76c915467c45059c63d2a7212f8a47", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "8f76c915467c45059c63d2a7212f8a47", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "47d867b1b9de41fabed3595626b5468d", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "7c2679dde90544c5b2c76ae01fd4f6a5", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "7c2679dde90544c5b2c76ae01fd4f6a5", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "7c2679dde90544c5b2c76ae01fd4f6a5", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "47d867b1b9de41fabed3595626b5468d", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "421d28b972784b11953a5758ca0e6d6f", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "421d28b972784b11953a5758ca0e6d6f", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "421d28b972784b11953a5758ca0e6d6f", "closed": false}
Before state_dict() in sharding manager: 26.15 GB / 93.02 GB.
After state_dict() in sharding manager: 26.22 GB / 93.02 GB.
INFO 05-04 19:39:00 [executor_base.py:226] It took 0.152852 seconds to wake up tags ['weights'].
After sync model weights in sharding manager: 33.53 GB / 93.02 GB.
INFO 05-04 19:39:00 [executor_base.py:226] It took 0.002490 seconds to wake up tags ['kv_cache'].
After del state_dict and empty_cache in sharding manager: 51.32 GB / 93.02 GB.
Before vllm offload in sharding manager: 51.32 GB / 93.02 GB.
INFO 05-04 19:39:03 [block_pool.py:264] Successfully reset prefix cache
INFO 05-04 19:39:04 [gpu_worker.py:81] Sleep mode freed 25.17 GiB memory, 26.15 GiB memory is still in use.
INFO 05-04 19:39:04 [executor_base.py:210] It took 0.589360 seconds to fall asleep.
After vllm offload in sharding manager: 26.15 GB / 93.02 GB.
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "82c4ec65fbbe4eb5939d821acdaef662", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "4b8f1f8720544f86b4bdcb49f65ff376", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 2, "desc": "Compute log probs ((rollout)responses per GPU / batch_size_per_device for experience)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "4b8f1f8720544f86b4bdcb49f65ff376", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "985a2317e88049d793a56e936234e5c2", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "134fe75e43884b6d818f0a88b4bd2f58", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 3, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "134fe75e43884b6d818f0a88b4bd2f58", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 5, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "134fe75e43884b6d818f0a88b4bd2f58", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 2, "desc": "Train mini-batches ((rollout)responses per_GPU / per_GPU [update]responses)", "total": 2, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "985a2317e88049d793a56e936234e5c2", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 1, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "ca52caa6935c454e83f7a22f0c9ae66f", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 2, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "ca52caa6935c454e83f7a22f0c9ae66f", "closed": false}
{"__magic_token__": "__ray_tqdm_magic_token__", "x": 4, "pos": 3, "desc": "Update policy ((update)responses per_GPU / batch_per_device_for_update)", "total": 5, "unit": "it", "ip": "10.153.51.195", "pid": 1927200, "uuid": "ca52caa6935c454e83f7a22f0c9ae66f", "closed": false}
Before state_dict() in sharding manager: 25.97 GB / 93.02 GB.
After state_dict() in sharding manager: 26.04 GB / 93.02 GB.
INFO 05-04 19:39:20 [executor_base.py:226] It took 0.162069 seconds to wake up tags ['weights'].
After sync model weights in sharding manager: 33.35 GB / 93.02 GB.
INFO 05-04 19:39:20 [executor_base.py:226] It took 0.004049 seconds to wake up tags ['kv_cache'].
After del state_dict and empty_cache in sharding manager: 51.14 GB / 93.02 GB.
