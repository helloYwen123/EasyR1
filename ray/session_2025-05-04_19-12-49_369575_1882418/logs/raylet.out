[2025-05-04 19:12:52,207 I 1883226 1883226] (raylet) main.cc:226: Setting cluster ID to: 680f492150b6eb2e22fd2803b8896f54ae4fbc82dea40e9bf643f8af
[2025-05-04 19:12:52,214 I 1883226 1883226] (raylet) main.cc:341: Raylet is not set to kill unknown children.
[2025-05-04 19:12:52,214 I 1883226 1883226] (raylet) io_service_pool.cc:35: IOServicePool is running with 1 io_service.
[2025-05-04 19:12:52,215 I 1883226 1883226] (raylet) main.cc:471: Setting node ID node_id=526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277
[2025-05-04 19:12:52,216 I 1883226 1883226] (raylet) store_runner.cc:33: Allowing the Plasma store to use up to 31.4674GB of memory.
[2025-05-04 19:12:52,218 I 1883226 1883226] (raylet) store_runner.cc:49: Starting object store with directory /dev/shm, fallback /home/stud/wxie/EasyR1/ray, and huge page support disabled
[2025-05-04 19:12:52,219 I 1883226 1883259] (raylet) dlmalloc.cc:154: create_and_mmap_buffer(31467503624, /dev/shm/plasmaXXXXXX)
[2025-05-04 19:12:52,228 I 1883226 1883259] (raylet) store.cc:564: Plasma store debug dump: 
Current usage: 0 / 31.4674 GB
- num bytes created total: 0
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 0
- bytes in use: 0
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 0
- bytes created by worker: 0
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2025-05-04 19:12:53,224 I 1883226 1883226] (raylet) grpc_server.cc:135: ObjectManager server started, listening on port 36939.
[2025-05-04 19:12:53,229 I 1883226 1883226] (raylet) worker_killing_policy.cc:101: Running GroupByOwner policy.
[2025-05-04 19:12:53,229 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:12:53,230 I 1883226 1883226] (raylet) memory_monitor.cc:48: MemoryMonitor initialized with usage threshold at 128114286592 bytes (0.95 system memory), total system memory bytes: 134857150464
[2025-05-04 19:12:53,230 I 1883226 1883226] (raylet) node_manager.cc:295: Initializing NodeManager node_id=526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277
[2025-05-04 19:12:53,231 I 1883226 1883226] (raylet) grpc_server.cc:135: NodeManager server started, listening on port 38103.
[2025-05-04 19:12:53,245 I 1883226 1883335] (raylet) agent_manager.cc:78: Monitor agent process with name dashboard_agent/424238335
[2025-05-04 19:12:53,245 I 1883226 1883337] (raylet) agent_manager.cc:78: Monitor agent process with name runtime_env_agent
[2025-05-04 19:12:53,247 I 1883226 1883226] (raylet) event.cc:500: Ray Event initialized for RAYLET
[2025-05-04 19:12:53,247 I 1883226 1883226] (raylet) event.cc:331: Set ray event level to warning
[2025-05-04 19:12:53,250 I 1883226 1883226] (raylet) raylet.cc:134: Raylet of id, 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277 started. Raylet consists of node_manager and object_manager. node_manager address: 10.153.51.195:38103 object_manager address: 10.153.51.195:36939 hostname: marajo
[2025-05-04 19:12:53,256 I 1883226 1883226] (raylet) node_manager.cc:532: [state-dump] NodeManager:
[state-dump] Node ID: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277
[state-dump] Node name: 10.153.51.195
[state-dump] InitialConfigResources: {object_store_memory: 314674102270000, node:10.153.51.195: 10000, node:__internal_head__: 10000, memory: 634239571970000, CPU: 320000, GPU: 10000, accelerator_type:H100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -8542947247730559774 Local resources: {"total":{node:10.153.51.195: [10000], object_store_memory: [314674102270000], accelerator_type:H100: [10000], node:__internal_head__: [10000], memory: [634239571970000], GPU: [10000], CPU: [320000]}}, "available": {node:10.153.51.195: [10000], object_store_memory: [314674102270000], accelerator_type:H100: [10000], node:__internal_head__: [10000], memory: [634239571970000], GPU: [10000], CPU: [320000]}}, "labels":{"ray.io/node_id":"526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277",} is_draining: 0 is_idle: 1 Cluster resources: node id: -8542947247730559774{"total":{accelerator_type:H100: 10000, CPU: 320000, node:__internal_head__: 10000, memory: 634239571970000, node:10.153.51.195: 10000, GPU: 10000, object_store_memory: 314674102270000}}, "available": {accelerator_type:H100: 10000, CPU: 320000, node:__internal_head__: 10000, memory: 634239571970000, node:10.153.51.195: 10000, GPU: 10000, object_store_memory: 314674102270000}}, "labels":{"ray.io/node_id":"526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277",}, "is_draining": 0, "draining_deadline_timestamp_ms": -1} { "placment group locations": [], "node to bundles": []}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump] }
[state-dump] Backlog Size per scheduling descriptor :{workerId: num backlogs}:
[state-dump] 
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 0
[state-dump] - pinned objects size: 0
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - num bytes currently spilled: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] - spilled objects pending delete: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 0
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num object pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 0 total (0 active)
[state-dump] Queueing time: mean = -nan s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] Execution time:  mean = -nan s, total = 0.000 s
[state-dump] Event stats:
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 0
[state-dump] - num location updates per second: 27502606465374400.000
[state-dump] - num location lookups per second: 27502606465369600.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 31467410227
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - get request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - wait request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - task request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 0
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num JAVA pending start requests: 0
[state-dump] - num JAVA pending registration requests: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 0
[state-dump] - num PYTHON drivers: 0
[state-dump] - num PYTHON pending start requests: 0
[state-dump] - num PYTHON pending registration requests: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 0
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 0
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 28 total (13 active)
[state-dump] Queueing time: mean = 2.597 ms, max = 17.688 ms, min = 16.460 us, total = 72.730 ms
[state-dump] Execution time:  mean = 37.308 ms, total = 1.045 s
[state-dump] Event stats:
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 11 total (2 active, 1 running), Execution time: mean = 478.207 us, total = 5.260 ms, Queueing time: mean = 6.605 ms, max = 17.688 ms, min = 53.447 us, total = 72.654 ms
[state-dump] 	ClusterResourceManager.ResetRemoteNodeView - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	MemoryMonitor.CheckIsMemoryUsageAboveThreshold - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), Execution time: mean = 2.987 ms, total = 2.987 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 1 total (0 active), Execution time: mean = 1.311 ms, total = 1.311 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ObjectManager.UpdateAvailableMemory - 1 total (0 active), Execution time: mean = 4.960 us, total = 4.960 us, Queueing time: mean = 23.696 us, max = 23.696 us, min = 23.696 us, total = 23.696 us
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.RegisterNode.OnReplyReceived - 1 total (0 active), Execution time: mean = 512.479 us, total = 512.479 us, Queueing time: mean = 35.181 us, max = 35.181 us, min = 35.181 us, total = 35.181 us
[state-dump] 	ray::rpc::InternalKVGcsService.grpc_client.GetInternalConfig - 1 total (0 active), Execution time: mean = 1.004 ms, total = 1.004 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch.OnReplyReceived - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.ScheduleAndDispatchTasks - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalKVGcsService.grpc_client.GetInternalConfig.OnReplyReceived - 1 total (0 active), Execution time: mean = 1.034 s, total = 1.034 s, Queueing time: mean = 16.460 us, max = 16.460 us, min = 16.460 us, total = 16.460 us
[state-dump] 	NodeManager.deadline_timer.spill_objects_when_over_threshold - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.GCTaskFailureReason - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] DebugString() time ms: 1
[state-dump] 
[state-dump] 
[2025-05-04 19:12:53,258 I 1883226 1883226] (raylet) accessor.cc:777: Received notification for node, IsAlive = 1 node_id=526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277
[2025-05-04 19:12:53,276 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883361, the token is 0
[2025-05-04 19:12:53,279 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883363, the token is 1
[2025-05-04 19:12:53,281 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883364, the token is 2
[2025-05-04 19:12:53,284 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883365, the token is 3
[2025-05-04 19:12:53,287 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883366, the token is 4
[2025-05-04 19:12:53,290 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883367, the token is 5
[2025-05-04 19:12:53,293 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883368, the token is 6
[2025-05-04 19:12:53,296 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883369, the token is 7
[2025-05-04 19:12:53,298 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883370, the token is 8
[2025-05-04 19:12:53,302 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883371, the token is 9
[2025-05-04 19:12:53,305 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883372, the token is 10
[2025-05-04 19:12:53,308 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883373, the token is 11
[2025-05-04 19:12:53,310 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883375, the token is 12
[2025-05-04 19:12:53,313 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883376, the token is 13
[2025-05-04 19:12:53,316 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883379, the token is 14
[2025-05-04 19:12:53,319 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883381, the token is 15
[2025-05-04 19:12:53,322 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883384, the token is 16
[2025-05-04 19:12:53,325 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883385, the token is 17
[2025-05-04 19:12:53,327 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883386, the token is 18
[2025-05-04 19:12:53,345 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883387, the token is 19
[2025-05-04 19:12:53,348 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883388, the token is 20
[2025-05-04 19:12:53,351 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883389, the token is 21
[2025-05-04 19:12:53,354 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883390, the token is 22
[2025-05-04 19:12:53,357 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883391, the token is 23
[2025-05-04 19:12:53,360 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883392, the token is 24
[2025-05-04 19:12:53,364 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883393, the token is 25
[2025-05-04 19:12:53,367 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883394, the token is 26
[2025-05-04 19:12:53,371 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883395, the token is 27
[2025-05-04 19:12:53,374 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883396, the token is 28
[2025-05-04 19:12:53,377 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883397, the token is 29
[2025-05-04 19:12:53,380 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883398, the token is 30
[2025-05-04 19:12:53,385 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1883400, the token is 31
[2025-05-04 19:12:54,666 I 1883226 1883259] (raylet) object_store.cc:35: Object store current usage 8e-09 / 31.4674 GB.
[2025-05-04 19:12:55,029 I 1883226 1883226] (raylet) worker_pool.cc:719: Job 01000000 already started in worker pool.
[2025-05-04 19:12:58,253 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:13:03,265 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:13:08,271 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:13:12,704 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:13:12,805 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:13:13,279 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:13:18,271 I 1883226 1883226] (raylet) runtime_env_agent_client.cc:383: Create runtime env for job 01000000
[2025-05-04 19:13:18,281 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1886580, the token is 32
[2025-05-04 19:13:18,285 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:13:19,289 I 1883226 1883226] (raylet) node_manager.cc:1549: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = false
[2025-05-04 19:13:19,711 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:13:20,012 I 1883226 1883226] (raylet) local_resource_manager.cc:288: Object store memory is idle.
[2025-05-04 19:13:23,299 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:13:28,305 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:13:30,964 I 1883226 1883226] (raylet) runtime_env_agent_client.cc:383: Create runtime env for job 01000000
[2025-05-04 19:13:30,974 I 1883226 1883226] (raylet) worker_pool.cc:522: Started worker process with pid 1887223, the token is 33
[2025-05-04 19:13:33,312 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:13:38,319 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:13:43,326 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:13:48,333 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:13:52,229 I 1883226 1883259] (raylet) store.cc:564: Plasma store debug dump: 
Current usage: 0 / 31.4674 GB
- num bytes created total: 10731970
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 0
- bytes in use: 0
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 0
- bytes created by worker: 0
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2025-05-04 19:13:53,257 I 1883226 1883226] (raylet) node_manager.cc:532: [state-dump] NodeManager:
[state-dump] Node ID: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277
[state-dump] Node name: 10.153.51.195
[state-dump] InitialConfigResources: {object_store_memory: 314674102270000, node:10.153.51.195: 10000, node:__internal_head__: 10000, memory: 634239571970000, CPU: 320000, GPU: 10000, accelerator_type:H100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -8542947247730559774 Local resources: {"total":{CPU_group_63639ba0c12292c9677a42d0630201000000: [10000], CPU_group_0_63639ba0c12292c9677a42d0630201000000: [10000], node:__internal_head__: [10000], memory: [634239571970000], GPU: [10000], accelerator_type:H100: [10000], node:10.153.51.195: [10000], object_store_memory: [314674102270000], bundle_group_0_63639ba0c12292c9677a42d0630201000000: [10000000], GPU_group_0_63639ba0c12292c9677a42d0630201000000: [10000], GPU_group_63639ba0c12292c9677a42d0630201000000: [10000], bundle_group_63639ba0c12292c9677a42d0630201000000: [10000000], CPU: [320000]}}, "available": {GPU: [0], GPU_group_0_63639ba0c12292c9677a42d0630201000000: [0], object_store_memory: [314674102270000], node:10.153.51.195: [10000], bundle_group_0_63639ba0c12292c9677a42d0630201000000: [9999990], CPU: [280000], bundle_group_63639ba0c12292c9677a42d0630201000000: [9999990], CPU_group_63639ba0c12292c9677a42d0630201000000: [0], node:__internal_head__: [10000], memory: [634239571970000], CPU_group_0_63639ba0c12292c9677a42d0630201000000: [0], GPU_group_63639ba0c12292c9677a42d0630201000000: [0], accelerator_type:H100: [10000]}}, "labels":{"ray.io/node_id":"526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277",} is_draining: 0 is_idle: 0 Cluster resources: node id: -8542947247730559774{"total":{CPU_group_63639ba0c12292c9677a42d0630201000000: 10000, CPU: 320000, bundle_group_63639ba0c12292c9677a42d0630201000000: 10000000, GPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, object_store_memory: 314674102270000, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 10000000, node:10.153.51.195: 10000, accelerator_type:H100: 10000, GPU_group_63639ba0c12292c9677a42d0630201000000: 10000, GPU: 10000, node:__internal_head__: 10000, memory: 634239571970000, CPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000}}, "available": {CPU: 280000, bundle_group_63639ba0c12292c9677a42d0630201000000: 9999990, object_store_memory: 314674102270000, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 9999990, node:10.153.51.195: 10000, accelerator_type:H100: 10000, memory: 634239571970000, node:__internal_head__: 10000}}, "labels":{"ray.io/node_id":"526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277",}, "is_draining": 0, "draining_deadline_timestamp_ms": -1} { "placment group locations": [], "node to bundles": []}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump]     - (language=PYTHON actor_or_task=WorkerDict.__init__ pid=1886580 worker_id=15629c5564e3fadc61478ea400fccad8e9ac6659227384271beb54b5): {CPU_group_63639ba0c12292c9677a42d0630201000000: 10000, GPU_group_63639ba0c12292c9677a42d0630201000000: 10000, bundle_group_63639ba0c12292c9677a42d0630201000000: 10, CPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, GPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 10}
[state-dump]     - (language=PYTHON actor_or_task=BatchFunctionRewardManager.__init__ pid=1883373 worker_id=35007cacb22a2ab9270518c3a772ef57ac2292cd841da293cf93474f): {CPU: 10000}
[state-dump]     - (language=PYTHON actor_or_task=BatchFunctionRewardManager.__init__ pid=1883367 worker_id=893b844e6104b8bfbe7ab227e5350214387d314adeb85bf2032d74b6): {CPU: 10000}
[state-dump]     - (language=PYTHON actor_or_task=Runner.__init__ pid=1883368 worker_id=2f42c986ad1cd9cfbffa7ff657d795fc9481e7ea1a2c40b84c354d78): {CPU: 10000}
[state-dump]     - (language=PYTHON actor_or_task=WorkerGroupRegisterCenter.__init__ pid=1887223 worker_id=bd8e336aca79943c2e026e1985cfc415588c98dd1f75efc08d91dc1f): {}
[state-dump] }
[state-dump] Backlog Size per scheduling descriptor :{workerId: num backlogs}:
[state-dump] 
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 0
[state-dump] - pinned objects size: 0
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - num bytes currently spilled: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] - spilled objects pending delete: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 0
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num object pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 1 total (0 active)
[state-dump] Queueing time: mean = 45.573 us, max = 45.573 us, min = 45.573 us, total = 45.573 us
[state-dump] Execution time:  mean = 60.054 us, total = 60.054 us
[state-dump] Event stats:
[state-dump] 	ObjectManager.FreeObjects - 1 total (0 active), Execution time: mean = 60.054 us, total = 60.054 us, Queueing time: mean = 45.573 us, max = 45.573 us, min = 45.573 us, total = 45.573 us
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 0
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 31467410227
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - get request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - wait request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - task request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 1
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num JAVA pending start requests: 0
[state-dump] - num JAVA pending registration requests: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 33
[state-dump] - num PYTHON drivers: 1
[state-dump] - num PYTHON pending start requests: 0
[state-dump] - num PYTHON pending registration requests: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 28
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 0
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 2
[state-dump] - cumulative unsubscribe requests: 2
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 2
[state-dump] - cumulative processed messages: 2
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 4
[state-dump] - cumulative unsubscribe requests: 4
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 7529 total (49 active)
[state-dump] Queueing time: mean = 24.363 ms, max = 24.240 s, min = -0.000 s, total = 183.432 s
[state-dump] Execution time:  mean = 5.363 ms, total = 40.380 s
[state-dump] Event stats:
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 1967 total (0 active), Execution time: mean = 456.830 us, total = 898.585 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog.HandleRequestImpl - 1967 total (0 active), Execution time: mean = 44.599 us, total = 87.727 ms, Queueing time: mean = 79.784 us, max = 4.123 ms, min = 5.981 us, total = 156.935 ms
[state-dump] 	ObjectManager.UpdateAvailableMemory - 600 total (0 active), Execution time: mean = 5.897 us, total = 3.538 ms, Queueing time: mean = 54.835 us, max = 503.560 us, min = 2.861 us, total = 32.901 ms
[state-dump] 	NodeManager.CheckGC - 600 total (1 active), Execution time: mean = 3.924 us, total = 2.354 ms, Queueing time: mean = 132.551 us, max = 27.165 ms, min = 10.289 us, total = 79.531 ms
[state-dump] 	RaySyncer.OnDemandBroadcasting - 600 total (1 active), Execution time: mean = 17.972 us, total = 10.783 ms, Queueing time: mean = 119.162 us, max = 27.147 ms, min = -0.000 s, total = 71.497 ms
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 300 total (1 active), Execution time: mean = 24.388 us, total = 7.316 ms, Queueing time: mean = 62.856 us, max = 499.934 us, min = 5.755 us, total = 18.857 ms
[state-dump] 	MemoryMonitor.CheckIsMemoryUsageAboveThreshold - 240 total (1 active), Execution time: mean = 277.124 us, total = 66.510 ms, Queueing time: mean = 105.060 us, max = 6.752 ms, min = 3.906 us, total = 25.214 ms
[state-dump] 	ClientConnection.async_read.ProcessMessageHeader - 161 total (34 active), Execution time: mean = 5.259 us, total = 846.661 us, Queueing time: mean = 1.133 s, max = 24.240 s, min = 15.763 us, total = 182.417 s
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats.OnReplyReceived - 134 total (0 active), Execution time: mean = 19.704 us, total = 2.640 ms, Queueing time: mean = 2.311 ms, max = 9.385 ms, min = 14.954 us, total = 309.650 ms
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 134 total (0 active), Execution time: mean = 1.234 ms, total = 165.348 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ClientConnection.async_read.ProcessMessage - 127 total (0 active), Execution time: mean = 979.528 us, total = 124.400 ms, Queueing time: mean = 19.219 us, max = 302.584 us, min = 1.809 us, total = 2.441 ms
[state-dump] 	NodeManager.ScheduleAndDispatchTasks - 61 total (1 active), Execution time: mean = 17.145 us, total = 1.046 ms, Queueing time: mean = 51.364 us, max = 135.225 us, min = 9.881 us, total = 3.133 ms
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 60 total (0 active), Execution time: mean = 701.171 us, total = 42.070 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad.HandleRequestImpl - 60 total (0 active), Execution time: mean = 158.607 us, total = 9.516 ms, Queueing time: mean = 88.001 us, max = 142.260 us, min = 23.684 us, total = 5.280 ms
[state-dump] 	NodeManager.deadline_timer.spill_objects_when_over_threshold - 60 total (1 active), Execution time: mean = 3.119 us, total = 187.122 us, Queueing time: mean = 880.852 us, max = 27.461 ms, min = 14.300 us, total = 52.851 ms
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 60 total (1 active), Execution time: mean = 15.192 us, total = 911.546 us, Queueing time: mean = 870.424 us, max = 27.634 ms, min = 17.523 us, total = 52.225 ms
[state-dump] 	ObjectManager.ObjectDeleted - 37 total (0 active), Execution time: mean = 19.047 us, total = 704.753 us, Queueing time: mean = 60.787 us, max = 311.924 us, min = 14.729 us, total = 2.249 ms
[state-dump] 	ObjectManager.ObjectAdded - 37 total (0 active), Execution time: mean = 44.608 us, total = 1.651 ms, Queueing time: mean = 21.310 us, max = 110.079 us, min = 5.784 us, total = 788.472 us
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 36 total (0 active), Execution time: mean = 997.167 ns, total = 35.898 us, Queueing time: mean = 23.162 us, max = 153.418 us, min = 6.601 us, total = 833.849 us
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig.HandleRequestImpl - 35 total (0 active), Execution time: mean = 33.161 us, total = 1.161 ms, Queueing time: mean = 43.025 us, max = 358.910 us, min = 7.361 us, total = 1.506 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 35 total (0 active), Execution time: mean = 267.125 us, total = 9.349 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ClusterResourceManager.ResetRemoteNodeView - 21 total (1 active), Execution time: mean = 9.695 us, total = 203.587 us, Queueing time: mean = 57.284 us, max = 110.103 us, min = 25.274 us, total = 1.203 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 13 total (0 active), Execution time: mean = 479.902 us, total = 6.239 ms, Queueing time: mean = 6.426 ms, max = 17.688 ms, min = 53.447 us, total = 83.543 ms
[state-dump] 	NodeManager.GcsCheckAlive - 12 total (1 active), Execution time: mean = 280.683 us, total = 3.368 ms, Queueing time: mean = 4.042 ms, max = 27.580 ms, min = 152.934 us, total = 48.507 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch.OnReplyReceived - 12 total (0 active), Execution time: mean = 183.894 us, total = 2.207 ms, Queueing time: mean = 66.448 us, max = 140.626 us, min = 14.886 us, total = 797.378 us
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.CheckAlive - 12 total (0 active), Execution time: mean = 1.459 ms, total = 17.505 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.CheckAlive.OnReplyReceived - 12 total (0 active), Execution time: mean = 73.872 us, total = 886.464 us, Queueing time: mean = 813.447 us, max = 9.081 ms, min = 21.601 us, total = 9.761 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 12 total (1 active), Execution time: mean = 661.141 us, total = 7.934 ms, Queueing time: mean = 3.715 ms, max = 27.358 ms, min = 26.247 us, total = 44.577 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 12 total (0 active), Execution time: mean = 1.165 ms, total = 13.977 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	RaySyncer.BroadcastMessage - 10 total (0 active), Execution time: mean = 243.284 us, total = 2.433 ms, Queueing time: mean = 508.800 ns, max = 1.052 us, min = 75.000 ns, total = 5.088 us
[state-dump] 	 - 10 total (0 active), Execution time: mean = 1.060 us, total = 10.598 us, Queueing time: mean = 56.659 us, max = 123.718 us, min = 17.545 us, total = 566.591 us
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 7 total (1 active), Execution time: mean = 1.051 s, total = 7.360 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease.HandleRequestImpl - 6 total (0 active), Execution time: mean = 359.743 us, total = 2.158 ms, Queueing time: mean = 39.346 us, max = 59.463 us, min = 25.826 us, total = 236.075 us
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 6 total (0 active), Execution time: mean = 718.247 ms, total = 4.309 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 6 total (1 active), Execution time: mean = 8.625 ms, total = 51.750 ms, Queueing time: mean = 47.681 us, max = 77.921 us, min = 35.103 us, total = 286.084 us
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling.OnReplyReceived - 6 total (0 active), Execution time: mean = 229.450 us, total = 1.377 ms, Queueing time: mean = 301.385 us, max = 673.763 us, min = 28.451 us, total = 1.808 ms
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 4 total (0 active), Execution time: mean = 7.916 ms, total = 31.663 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats.HandleRequestImpl - 4 total (0 active), Execution time: mean = 6.657 ms, total = 26.628 ms, Queueing time: mean = 87.868 us, max = 143.854 us, min = 44.753 us, total = 351.473 us
[state-dump] 	WorkerPool.PopWorkerCallback - 4 total (0 active), Execution time: mean = 42.575 us, total = 170.300 us, Queueing time: mean = 14.928 us, max = 18.224 us, min = 7.758 us, total = 59.711 us
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch.OnReplyReceived - 4 total (0 active), Execution time: mean = 129.119 us, total = 516.478 us, Queueing time: mean = 55.842 us, max = 126.774 us, min = 30.884 us, total = 223.369 us
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 4 total (0 active), Execution time: mean = 1.466 ms, total = 5.866 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 3 total (1 active), Execution time: mean = 8.681 s, total = 26.042 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 2 total (0 active), Execution time: mean = 1.340 ms, total = 2.681 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	RaySyncerRegister - 2 total (0 active), Execution time: mean = 2.406 us, total = 4.812 us, Queueing time: mean = 399.000 ns, max = 725.000 ns, min = 73.000 ns, total = 798.000 ns
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll.OnReplyReceived - 2 total (0 active), Execution time: mean = 249.147 us, total = 498.293 us, Queueing time: mean = 39.880 us, max = 56.731 us, min = 23.029 us, total = 79.760 us
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs.HandleRequestImpl - 2 total (0 active), Execution time: mean = 685.252 us, total = 1.371 ms, Queueing time: mean = 136.399 us, max = 242.668 us, min = 30.130 us, total = 272.798 us
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 2 total (0 active), Execution time: mean = 1.095 ms, total = 2.190 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 2 total (0 active), Execution time: mean = 238.420 us, total = 476.840 us, Queueing time: mean = 323.839 us, max = 382.201 us, min = 265.477 us, total = 647.678 us
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch.OnReplyReceived - 2 total (0 active), Execution time: mean = 116.618 us, total = 233.237 us, Queueing time: mean = 2.480 ms, max = 4.935 ms, min = 24.523 us, total = 4.959 ms
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.RegisterNode.OnReplyReceived - 1 total (0 active), Execution time: mean = 512.479 us, total = 512.479 us, Queueing time: mean = 35.181 us, max = 35.181 us, min = 35.181 us, total = 35.181 us
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 1 total (1 active, 1 running), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), Execution time: mean = 942.762 us, total = 942.762 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 1 total (0 active), Execution time: mean = 14.970 us, total = 14.970 us, Queueing time: mean = 406.268 us, max = 406.268 us, min = 406.268 us, total = 406.268 us
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 130.863 us, total = 130.863 us, Queueing time: mean = 46.091 us, max = 46.091 us, min = 46.091 us, total = 46.091 us
[state-dump] 	NodeManagerService.grpc_server.ReturnWorker - 1 total (0 active), Execution time: mean = 596.261 us, total = 596.261 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.ReturnWorker.HandleRequestImpl - 1 total (0 active), Execution time: mean = 176.782 us, total = 176.782 us, Queueing time: mean = 19.047 us, max = 19.047 us, min = 19.047 us, total = 19.047 us
[state-dump] 	NodeManagerService.grpc_server.PrepareBundleResources - 1 total (0 active), Execution time: mean = 659.308 us, total = 659.308 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	CoreWorkerService.grpc_client.Exit - 1 total (0 active), Execution time: mean = 1.657 ms, total = 1.657 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalKVGcsService.grpc_client.GetInternalConfig - 1 total (0 active), Execution time: mean = 1.004 ms, total = 1.004 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), Execution time: mean = 48.288 us, total = 48.288 us, Queueing time: mean = 73.934 us, max = 73.934 us, min = 73.934 us, total = 73.934 us
[state-dump] 	CoreWorkerService.grpc_client.Exit.OnReplyReceived - 1 total (0 active), Execution time: mean = 67.247 us, total = 67.247 us, Queueing time: mean = 60.293 us, max = 60.293 us, min = 60.293 us, total = 60.293 us
[state-dump] 	ray::rpc::WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 1 total (0 active), Execution time: mean = 3.719 ms, total = 3.719 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.PrepareBundleResources.HandleRequestImpl - 1 total (0 active), Execution time: mean = 354.575 us, total = 354.575 us, Queueing time: mean = 26.490 us, max = 26.490 us, min = 26.490 us, total = 26.490 us
[state-dump] 	NodeManagerService.grpc_server.CommitBundleResources.HandleRequestImpl - 1 total (0 active), Execution time: mean = 382.745 us, total = 382.745 us, Queueing time: mean = 43.513 us, max = 43.513 us, min = 43.513 us, total = 43.513 us
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), Execution time: mean = 1.494 ms, total = 1.494 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::WorkerInfoGcsService.grpc_client.ReportWorkerFailure.OnReplyReceived - 1 total (0 active), Execution time: mean = 30.591 us, total = 30.591 us, Queueing time: mean = 440.325 us, max = 440.325 us, min = 440.325 us, total = 440.325 us
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.GetAllJobInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 15.904 us, total = 15.904 us, Queueing time: mean = 24.348 us, max = 24.348 us, min = 24.348 us, total = 24.348 us
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), Execution time: mean = 674.721 us, total = 674.721 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), Execution time: mean = 2.987 ms, total = 2.987 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.AddJob.OnReplyReceived - 1 total (0 active), Execution time: mean = 44.604 us, total = 44.604 us, Queueing time: mean = 22.684 us, max = 22.684 us, min = 22.684 us, total = 22.684 us
[state-dump] 	NodeManagerService.grpc_server.CommitBundleResources - 1 total (0 active), Execution time: mean = 549.781 us, total = 549.781 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalKVGcsService.grpc_client.GetInternalConfig.OnReplyReceived - 1 total (0 active), Execution time: mean = 1.034 s, total = 1.034 s, Queueing time: mean = 16.460 us, max = 16.460 us, min = 16.460 us, total = 16.460 us
[state-dump] 	NodeManager.GCTaskFailureReason - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] DebugString() time ms: 1
[state-dump] 
[state-dump] 
[2025-05-04 19:13:53,339 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:13:58,345 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:14:03,351 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:14:08,357 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:14:13,364 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:14:18,370 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:14:23,377 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:14:28,384 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:14:33,390 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:14:38,396 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:14:43,402 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:14:48,409 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:14:52,229 I 1883226 1883259] (raylet) store.cc:564: Plasma store debug dump: 
Current usage: 0 / 31.4674 GB
- num bytes created total: 10731970
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 0
- bytes in use: 0
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 0
- bytes created by worker: 0
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2025-05-04 19:14:53,260 I 1883226 1883226] (raylet) node_manager.cc:532: [state-dump] NodeManager:
[state-dump] Node ID: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277
[state-dump] Node name: 10.153.51.195
[state-dump] InitialConfigResources: {object_store_memory: 314674102270000, node:10.153.51.195: 10000, node:__internal_head__: 10000, memory: 634239571970000, CPU: 320000, GPU: 10000, accelerator_type:H100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -8542947247730559774 Local resources: {"total":{CPU_group_63639ba0c12292c9677a42d0630201000000: [10000], CPU_group_0_63639ba0c12292c9677a42d0630201000000: [10000], node:__internal_head__: [10000], memory: [634239571970000], GPU: [10000], accelerator_type:H100: [10000], node:10.153.51.195: [10000], object_store_memory: [314674102270000], bundle_group_0_63639ba0c12292c9677a42d0630201000000: [10000000], GPU_group_0_63639ba0c12292c9677a42d0630201000000: [10000], GPU_group_63639ba0c12292c9677a42d0630201000000: [10000], bundle_group_63639ba0c12292c9677a42d0630201000000: [10000000], CPU: [320000]}}, "available": {GPU: [0], GPU_group_0_63639ba0c12292c9677a42d0630201000000: [0], object_store_memory: [314674102270000], node:10.153.51.195: [10000], bundle_group_0_63639ba0c12292c9677a42d0630201000000: [9999990], CPU: [280000], bundle_group_63639ba0c12292c9677a42d0630201000000: [9999990], CPU_group_63639ba0c12292c9677a42d0630201000000: [0], node:__internal_head__: [10000], memory: [634239571970000], CPU_group_0_63639ba0c12292c9677a42d0630201000000: [0], GPU_group_63639ba0c12292c9677a42d0630201000000: [0], accelerator_type:H100: [10000]}}, "labels":{"ray.io/node_id":"526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277",} is_draining: 0 is_idle: 0 Cluster resources: node id: -8542947247730559774{"total":{CPU_group_63639ba0c12292c9677a42d0630201000000: 10000, CPU: 320000, bundle_group_63639ba0c12292c9677a42d0630201000000: 10000000, GPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, object_store_memory: 314674102270000, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 10000000, node:10.153.51.195: 10000, accelerator_type:H100: 10000, GPU_group_63639ba0c12292c9677a42d0630201000000: 10000, GPU: 10000, node:__internal_head__: 10000, memory: 634239571970000, CPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000}}, "available": {CPU: 280000, bundle_group_63639ba0c12292c9677a42d0630201000000: 9999990, object_store_memory: 314674102270000, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 9999990, node:10.153.51.195: 10000, accelerator_type:H100: 10000, memory: 634239571970000, node:__internal_head__: 10000}}, "labels":{"ray.io/node_id":"526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277",}, "is_draining": 0, "draining_deadline_timestamp_ms": -1} { "placment group locations": [], "node to bundles": []}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump]     - (language=PYTHON actor_or_task=WorkerDict.__init__ pid=1886580 worker_id=15629c5564e3fadc61478ea400fccad8e9ac6659227384271beb54b5): {CPU_group_63639ba0c12292c9677a42d0630201000000: 10000, GPU_group_63639ba0c12292c9677a42d0630201000000: 10000, bundle_group_63639ba0c12292c9677a42d0630201000000: 10, CPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, GPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 10}
[state-dump]     - (language=PYTHON actor_or_task=BatchFunctionRewardManager.__init__ pid=1883373 worker_id=35007cacb22a2ab9270518c3a772ef57ac2292cd841da293cf93474f): {CPU: 10000}
[state-dump]     - (language=PYTHON actor_or_task=BatchFunctionRewardManager.__init__ pid=1883367 worker_id=893b844e6104b8bfbe7ab227e5350214387d314adeb85bf2032d74b6): {CPU: 10000}
[state-dump]     - (language=PYTHON actor_or_task=Runner.__init__ pid=1883368 worker_id=2f42c986ad1cd9cfbffa7ff657d795fc9481e7ea1a2c40b84c354d78): {CPU: 10000}
[state-dump]     - (language=PYTHON actor_or_task=WorkerGroupRegisterCenter.__init__ pid=1887223 worker_id=bd8e336aca79943c2e026e1985cfc415588c98dd1f75efc08d91dc1f): {}
[state-dump] }
[state-dump] Backlog Size per scheduling descriptor :{workerId: num backlogs}:
[state-dump] 
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 0
[state-dump] - pinned objects size: 0
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - num bytes currently spilled: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] - spilled objects pending delete: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 0
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num object pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 1 total (0 active)
[state-dump] Queueing time: mean = 45.573 us, max = 45.573 us, min = 45.573 us, total = 45.573 us
[state-dump] Execution time:  mean = 60.054 us, total = 60.054 us
[state-dump] Event stats:
[state-dump] 	ObjectManager.FreeObjects - 1 total (0 active), Execution time: mean = 60.054 us, total = 60.054 us, Queueing time: mean = 45.573 us, max = 45.573 us, min = 45.573 us, total = 45.573 us
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 0
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 31467410227
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - get request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - wait request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - task request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 1
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num JAVA pending start requests: 0
[state-dump] - num JAVA pending registration requests: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 33
[state-dump] - num PYTHON drivers: 1
[state-dump] - num PYTHON pending start requests: 0
[state-dump] - num PYTHON pending registration requests: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 28
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 0
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 2
[state-dump] - cumulative unsubscribe requests: 2
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 2
[state-dump] - cumulative processed messages: 2
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 4
[state-dump] - cumulative unsubscribe requests: 4
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 14601 total (49 active)
[state-dump] Queueing time: mean = 12.600 ms, max = 24.240 s, min = -0.000 s, total = 183.968 s
[state-dump] Execution time:  mean = 2.851 ms, total = 41.631 s
[state-dump] Event stats:
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 4007 total (0 active), Execution time: mean = 430.692 us, total = 1.726 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog.HandleRequestImpl - 4007 total (0 active), Execution time: mean = 41.607 us, total = 166.721 ms, Queueing time: mean = 69.876 us, max = 4.123 ms, min = 2.239 us, total = 279.993 ms
[state-dump] 	ObjectManager.UpdateAvailableMemory - 1199 total (0 active), Execution time: mean = 5.697 us, total = 6.830 ms, Queueing time: mean = 49.200 us, max = 503.560 us, min = 2.861 us, total = 58.990 ms
[state-dump] 	NodeManager.CheckGC - 1199 total (1 active), Execution time: mean = 3.964 us, total = 4.752 ms, Queueing time: mean = 106.759 us, max = 27.165 ms, min = 4.308 us, total = 128.005 ms
[state-dump] 	RaySyncer.OnDemandBroadcasting - 1199 total (1 active), Execution time: mean = 15.245 us, total = 18.279 ms, Queueing time: mean = 96.121 us, max = 27.147 ms, min = -0.000 s, total = 115.248 ms
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 600 total (1 active), Execution time: mean = 22.208 us, total = 13.325 ms, Queueing time: mean = 54.827 us, max = 499.934 us, min = 5.755 us, total = 32.896 ms
[state-dump] 	MemoryMonitor.CheckIsMemoryUsageAboveThreshold - 480 total (1 active), Execution time: mean = 274.135 us, total = 131.585 ms, Queueing time: mean = 78.614 us, max = 6.752 ms, min = 3.906 us, total = 37.735 ms
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats.OnReplyReceived - 270 total (0 active), Execution time: mean = 18.310 us, total = 4.944 ms, Queueing time: mean = 1.724 ms, max = 9.385 ms, min = 4.987 us, total = 465.506 ms
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 270 total (0 active), Execution time: mean = 1.044 ms, total = 281.870 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ClientConnection.async_read.ProcessMessageHeader - 161 total (34 active), Execution time: mean = 5.259 us, total = 846.661 us, Queueing time: mean = 1.133 s, max = 24.240 s, min = 15.763 us, total = 182.417 s
[state-dump] 	ClientConnection.async_read.ProcessMessage - 127 total (0 active), Execution time: mean = 979.528 us, total = 124.400 ms, Queueing time: mean = 19.219 us, max = 302.584 us, min = 1.809 us, total = 2.441 ms
[state-dump] 	NodeManager.ScheduleAndDispatchTasks - 121 total (1 active), Execution time: mean = 17.776 us, total = 2.151 ms, Queueing time: mean = 53.710 us, max = 170.082 us, min = 9.881 us, total = 6.499 ms
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 120 total (0 active), Execution time: mean = 673.194 us, total = 80.783 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad.HandleRequestImpl - 120 total (0 active), Execution time: mean = 164.184 us, total = 19.702 ms, Queueing time: mean = 79.282 us, max = 142.260 us, min = 23.427 us, total = 9.514 ms
[state-dump] 	NodeManager.deadline_timer.spill_objects_when_over_threshold - 120 total (1 active), Execution time: mean = 3.161 us, total = 379.347 us, Queueing time: mean = 677.370 us, max = 27.461 ms, min = 7.334 us, total = 81.284 ms
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 120 total (1 active), Execution time: mean = 12.853 us, total = 1.542 ms, Queueing time: mean = 669.602 us, max = 27.634 ms, min = 8.304 us, total = 80.352 ms
[state-dump] 	ClusterResourceManager.ResetRemoteNodeView - 41 total (1 active), Execution time: mean = 10.518 us, total = 431.249 us, Queueing time: mean = 58.173 us, max = 113.390 us, min = 13.675 us, total = 2.385 ms
[state-dump] 	ObjectManager.ObjectDeleted - 37 total (0 active), Execution time: mean = 19.047 us, total = 704.753 us, Queueing time: mean = 60.787 us, max = 311.924 us, min = 14.729 us, total = 2.249 ms
[state-dump] 	ObjectManager.ObjectAdded - 37 total (0 active), Execution time: mean = 44.608 us, total = 1.651 ms, Queueing time: mean = 21.310 us, max = 110.079 us, min = 5.784 us, total = 788.472 us
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 36 total (0 active), Execution time: mean = 997.167 ns, total = 35.898 us, Queueing time: mean = 23.162 us, max = 153.418 us, min = 6.601 us, total = 833.849 us
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig.HandleRequestImpl - 35 total (0 active), Execution time: mean = 33.161 us, total = 1.161 ms, Queueing time: mean = 43.025 us, max = 358.910 us, min = 7.361 us, total = 1.506 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 35 total (0 active), Execution time: mean = 267.125 us, total = 9.349 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.GcsCheckAlive - 24 total (1 active), Execution time: mean = 290.709 us, total = 6.977 ms, Queueing time: mean = 3.063 ms, max = 27.580 ms, min = 152.934 us, total = 73.515 ms
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.CheckAlive - 24 total (0 active), Execution time: mean = 1.445 ms, total = 34.684 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.CheckAlive.OnReplyReceived - 24 total (0 active), Execution time: mean = 63.644 us, total = 1.527 ms, Queueing time: mean = 428.763 us, max = 9.081 ms, min = 21.601 us, total = 10.290 ms
[state-dump] 	NodeManager.deadline_timer.record_metrics - 24 total (1 active), Execution time: mean = 633.487 us, total = 15.204 ms, Queueing time: mean = 2.749 ms, max = 27.358 ms, min = 26.247 us, total = 65.969 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 13 total (0 active), Execution time: mean = 479.902 us, total = 6.239 ms, Queueing time: mean = 6.426 ms, max = 17.688 ms, min = 53.447 us, total = 83.543 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch.OnReplyReceived - 12 total (0 active), Execution time: mean = 183.894 us, total = 2.207 ms, Queueing time: mean = 66.448 us, max = 140.626 us, min = 14.886 us, total = 797.378 us
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 12 total (0 active), Execution time: mean = 1.165 ms, total = 13.977 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 12 total (1 active), Execution time: mean = 6.712 ms, total = 80.547 ms, Queueing time: mean = 44.069 us, max = 77.921 us, min = 29.210 us, total = 528.834 us
[state-dump] 	 - 10 total (0 active), Execution time: mean = 1.060 us, total = 10.598 us, Queueing time: mean = 56.659 us, max = 123.718 us, min = 17.545 us, total = 566.591 us
[state-dump] 	RaySyncer.BroadcastMessage - 10 total (0 active), Execution time: mean = 243.284 us, total = 2.433 ms, Queueing time: mean = 508.800 ns, max = 1.052 us, min = 75.000 ns, total = 5.088 us
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats.HandleRequestImpl - 8 total (0 active), Execution time: mean = 5.065 ms, total = 40.519 ms, Queueing time: mean = 70.897 us, max = 143.854 us, min = 25.489 us, total = 567.180 us
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 8 total (0 active), Execution time: mean = 6.218 ms, total = 49.744 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 7 total (1 active), Execution time: mean = 1.051 s, total = 7.360 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease.HandleRequestImpl - 6 total (0 active), Execution time: mean = 359.743 us, total = 2.158 ms, Queueing time: mean = 39.346 us, max = 59.463 us, min = 25.826 us, total = 236.075 us
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling.OnReplyReceived - 6 total (0 active), Execution time: mean = 229.450 us, total = 1.377 ms, Queueing time: mean = 301.385 us, max = 673.763 us, min = 28.451 us, total = 1.808 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 6 total (0 active), Execution time: mean = 718.247 ms, total = 4.309 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	WorkerPool.PopWorkerCallback - 4 total (0 active), Execution time: mean = 42.575 us, total = 170.300 us, Queueing time: mean = 14.928 us, max = 18.224 us, min = 7.758 us, total = 59.711 us
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch.OnReplyReceived - 4 total (0 active), Execution time: mean = 129.119 us, total = 516.478 us, Queueing time: mean = 55.842 us, max = 126.774 us, min = 30.884 us, total = 223.369 us
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 4 total (0 active), Execution time: mean = 1.466 ms, total = 5.866 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 3 total (1 active), Execution time: mean = 8.681 s, total = 26.042 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs.HandleRequestImpl - 2 total (0 active), Execution time: mean = 685.252 us, total = 1.371 ms, Queueing time: mean = 136.399 us, max = 242.668 us, min = 30.130 us, total = 272.798 us
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 2 total (0 active), Execution time: mean = 1.340 ms, total = 2.681 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	RaySyncerRegister - 2 total (0 active), Execution time: mean = 2.406 us, total = 4.812 us, Queueing time: mean = 399.000 ns, max = 725.000 ns, min = 73.000 ns, total = 798.000 ns
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll.OnReplyReceived - 2 total (0 active), Execution time: mean = 249.147 us, total = 498.293 us, Queueing time: mean = 39.880 us, max = 56.731 us, min = 23.029 us, total = 79.760 us
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch.OnReplyReceived - 2 total (0 active), Execution time: mean = 116.618 us, total = 233.237 us, Queueing time: mean = 2.480 ms, max = 4.935 ms, min = 24.523 us, total = 4.959 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 2 total (0 active), Execution time: mean = 1.095 ms, total = 2.190 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 2 total (0 active), Execution time: mean = 238.420 us, total = 476.840 us, Queueing time: mean = 323.839 us, max = 382.201 us, min = 265.477 us, total = 647.678 us
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 2 total (1 active, 1 running), Execution time: mean = 503.127 us, total = 1.006 ms, Queueing time: mean = 13.107 us, max = 26.214 us, min = 26.214 us, total = 26.214 us
[state-dump] 	NodeManagerService.grpc_server.ReturnWorker - 1 total (0 active), Execution time: mean = 596.261 us, total = 596.261 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.RegisterNode.OnReplyReceived - 1 total (0 active), Execution time: mean = 512.479 us, total = 512.479 us, Queueing time: mean = 35.181 us, max = 35.181 us, min = 35.181 us, total = 35.181 us
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), Execution time: mean = 942.762 us, total = 942.762 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 130.863 us, total = 130.863 us, Queueing time: mean = 46.091 us, max = 46.091 us, min = 46.091 us, total = 46.091 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 1 total (0 active), Execution time: mean = 14.970 us, total = 14.970 us, Queueing time: mean = 406.268 us, max = 406.268 us, min = 406.268 us, total = 406.268 us
[state-dump] 	NodeManagerService.grpc_server.ReturnWorker.HandleRequestImpl - 1 total (0 active), Execution time: mean = 176.782 us, total = 176.782 us, Queueing time: mean = 19.047 us, max = 19.047 us, min = 19.047 us, total = 19.047 us
[state-dump] 	NodeManagerService.grpc_server.PrepareBundleResources - 1 total (0 active), Execution time: mean = 659.308 us, total = 659.308 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	CoreWorkerService.grpc_client.Exit - 1 total (0 active), Execution time: mean = 1.657 ms, total = 1.657 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalKVGcsService.grpc_client.GetInternalConfig - 1 total (0 active), Execution time: mean = 1.004 ms, total = 1.004 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), Execution time: mean = 48.288 us, total = 48.288 us, Queueing time: mean = 73.934 us, max = 73.934 us, min = 73.934 us, total = 73.934 us
[state-dump] 	CoreWorkerService.grpc_client.Exit.OnReplyReceived - 1 total (0 active), Execution time: mean = 67.247 us, total = 67.247 us, Queueing time: mean = 60.293 us, max = 60.293 us, min = 60.293 us, total = 60.293 us
[state-dump] 	ray::rpc::WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 1 total (0 active), Execution time: mean = 3.719 ms, total = 3.719 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.PrepareBundleResources.HandleRequestImpl - 1 total (0 active), Execution time: mean = 354.575 us, total = 354.575 us, Queueing time: mean = 26.490 us, max = 26.490 us, min = 26.490 us, total = 26.490 us
[state-dump] 	NodeManagerService.grpc_server.CommitBundleResources.HandleRequestImpl - 1 total (0 active), Execution time: mean = 382.745 us, total = 382.745 us, Queueing time: mean = 43.513 us, max = 43.513 us, min = 43.513 us, total = 43.513 us
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), Execution time: mean = 1.494 ms, total = 1.494 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::WorkerInfoGcsService.grpc_client.ReportWorkerFailure.OnReplyReceived - 1 total (0 active), Execution time: mean = 30.591 us, total = 30.591 us, Queueing time: mean = 440.325 us, max = 440.325 us, min = 440.325 us, total = 440.325 us
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.GetAllJobInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 15.904 us, total = 15.904 us, Queueing time: mean = 24.348 us, max = 24.348 us, min = 24.348 us, total = 24.348 us
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), Execution time: mean = 674.721 us, total = 674.721 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), Execution time: mean = 2.987 ms, total = 2.987 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.AddJob.OnReplyReceived - 1 total (0 active), Execution time: mean = 44.604 us, total = 44.604 us, Queueing time: mean = 22.684 us, max = 22.684 us, min = 22.684 us, total = 22.684 us
[state-dump] 	NodeManagerService.grpc_server.CommitBundleResources - 1 total (0 active), Execution time: mean = 549.781 us, total = 549.781 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalKVGcsService.grpc_client.GetInternalConfig.OnReplyReceived - 1 total (0 active), Execution time: mean = 1.034 s, total = 1.034 s, Queueing time: mean = 16.460 us, max = 16.460 us, min = 16.460 us, total = 16.460 us
[state-dump] 	NodeManager.GCTaskFailureReason - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] DebugString() time ms: 2
[state-dump] 
[state-dump] 
[2025-05-04 19:14:53,416 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:14:58,423 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:03,429 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:08,436 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:13,443 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:18,449 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:23,455 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:28,461 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:33,467 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:38,472 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:43,477 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:48,482 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:52,229 I 1883226 1883259] (raylet) store.cc:564: Plasma store debug dump: 
Current usage: 0 / 31.4674 GB
- num bytes created total: 10731970
0 pending objects of total size 0MB
- objects spillable: 0
- bytes spillable: 0
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 0
- bytes in use: 0
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 0
- bytes created by worker: 0
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2025-05-04 19:15:53,263 I 1883226 1883226] (raylet) node_manager.cc:532: [state-dump] NodeManager:
[state-dump] Node ID: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277
[state-dump] Node name: 10.153.51.195
[state-dump] InitialConfigResources: {object_store_memory: 314674102270000, node:10.153.51.195: 10000, node:__internal_head__: 10000, memory: 634239571970000, CPU: 320000, GPU: 10000, accelerator_type:H100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -8542947247730559774 Local resources: {"total":{CPU_group_63639ba0c12292c9677a42d0630201000000: [10000], CPU_group_0_63639ba0c12292c9677a42d0630201000000: [10000], node:__internal_head__: [10000], memory: [634239571970000], GPU: [10000], accelerator_type:H100: [10000], node:10.153.51.195: [10000], object_store_memory: [314674102270000], bundle_group_0_63639ba0c12292c9677a42d0630201000000: [10000000], GPU_group_0_63639ba0c12292c9677a42d0630201000000: [10000], GPU_group_63639ba0c12292c9677a42d0630201000000: [10000], bundle_group_63639ba0c12292c9677a42d0630201000000: [10000000], CPU: [320000]}}, "available": {GPU: [0], GPU_group_0_63639ba0c12292c9677a42d0630201000000: [0], object_store_memory: [314674102270000], node:10.153.51.195: [10000], bundle_group_0_63639ba0c12292c9677a42d0630201000000: [9999990], CPU: [280000], bundle_group_63639ba0c12292c9677a42d0630201000000: [9999990], CPU_group_63639ba0c12292c9677a42d0630201000000: [0], node:__internal_head__: [10000], memory: [634239571970000], CPU_group_0_63639ba0c12292c9677a42d0630201000000: [0], GPU_group_63639ba0c12292c9677a42d0630201000000: [0], accelerator_type:H100: [10000]}}, "labels":{"ray.io/node_id":"526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277",} is_draining: 0 is_idle: 0 Cluster resources: node id: -8542947247730559774{"total":{CPU_group_63639ba0c12292c9677a42d0630201000000: 10000, CPU: 320000, bundle_group_63639ba0c12292c9677a42d0630201000000: 10000000, GPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, object_store_memory: 314674102270000, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 10000000, node:10.153.51.195: 10000, accelerator_type:H100: 10000, GPU_group_63639ba0c12292c9677a42d0630201000000: 10000, GPU: 10000, node:__internal_head__: 10000, memory: 634239571970000, CPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000}}, "available": {CPU: 280000, bundle_group_63639ba0c12292c9677a42d0630201000000: 9999990, object_store_memory: 314674102270000, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 9999990, node:10.153.51.195: 10000, accelerator_type:H100: 10000, memory: 634239571970000, node:__internal_head__: 10000}}, "labels":{"ray.io/node_id":"526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277",}, "is_draining": 0, "draining_deadline_timestamp_ms": -1} { "placment group locations": [], "node to bundles": []}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump]     - (language=PYTHON actor_or_task=WorkerDict.__init__ pid=1886580 worker_id=15629c5564e3fadc61478ea400fccad8e9ac6659227384271beb54b5): {CPU_group_63639ba0c12292c9677a42d0630201000000: 10000, GPU_group_63639ba0c12292c9677a42d0630201000000: 10000, bundle_group_63639ba0c12292c9677a42d0630201000000: 10, CPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, GPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 10}
[state-dump]     - (language=PYTHON actor_or_task=BatchFunctionRewardManager.__init__ pid=1883373 worker_id=35007cacb22a2ab9270518c3a772ef57ac2292cd841da293cf93474f): {CPU: 10000}
[state-dump]     - (language=PYTHON actor_or_task=BatchFunctionRewardManager.__init__ pid=1883367 worker_id=893b844e6104b8bfbe7ab227e5350214387d314adeb85bf2032d74b6): {CPU: 10000}
[state-dump]     - (language=PYTHON actor_or_task=Runner.__init__ pid=1883368 worker_id=2f42c986ad1cd9cfbffa7ff657d795fc9481e7ea1a2c40b84c354d78): {CPU: 10000}
[state-dump]     - (language=PYTHON actor_or_task=WorkerGroupRegisterCenter.__init__ pid=1887223 worker_id=bd8e336aca79943c2e026e1985cfc415588c98dd1f75efc08d91dc1f): {}
[state-dump] }
[state-dump] Backlog Size per scheduling descriptor :{workerId: num backlogs}:
[state-dump] 
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 0
[state-dump] - pinned objects size: 0
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - num bytes currently spilled: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] - spilled objects pending delete: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 0
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num object pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 1 total (0 active)
[state-dump] Queueing time: mean = 45.573 us, max = 45.573 us, min = 45.573 us, total = 45.573 us
[state-dump] Execution time:  mean = 60.054 us, total = 60.054 us
[state-dump] Event stats:
[state-dump] 	ObjectManager.FreeObjects - 1 total (0 active), Execution time: mean = 60.054 us, total = 60.054 us, Queueing time: mean = 45.573 us, max = 45.573 us, min = 45.573 us, total = 45.573 us
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 0
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.000
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 31467410227
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - get request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - wait request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - task request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 1
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num JAVA pending start requests: 0
[state-dump] - num JAVA pending registration requests: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 33
[state-dump] - num PYTHON drivers: 1
[state-dump] - num PYTHON pending start requests: 0
[state-dump] - num PYTHON pending registration requests: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 28
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 0
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 2
[state-dump] - cumulative unsubscribe requests: 2
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 2
[state-dump] - cumulative processed messages: 2
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 4
[state-dump] - cumulative unsubscribe requests: 4
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 21678 total (49 active)
[state-dump] Queueing time: mean = 14.127 ms, max = 121.716 s, min = -0.000 s, total = 306.247 s
[state-dump] Execution time:  mean = 1.976 ms, total = 42.840 s
[state-dump] Event stats:
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 6047 total (0 active), Execution time: mean = 408.032 us, total = 2.467 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog.HandleRequestImpl - 6047 total (0 active), Execution time: mean = 39.420 us, total = 238.371 ms, Queueing time: mean = 64.404 us, max = 4.123 ms, min = 2.239 us, total = 389.449 ms
[state-dump] 	ObjectManager.UpdateAvailableMemory - 1799 total (0 active), Execution time: mean = 5.521 us, total = 9.932 ms, Queueing time: mean = 45.530 us, max = 503.560 us, min = 2.861 us, total = 81.908 ms
[state-dump] 	NodeManager.CheckGC - 1799 total (1 active), Execution time: mean = 3.834 us, total = 6.898 ms, Queueing time: mean = 92.466 us, max = 27.165 ms, min = 4.308 us, total = 166.346 ms
[state-dump] 	RaySyncer.OnDemandBroadcasting - 1799 total (1 active), Execution time: mean = 13.689 us, total = 24.627 ms, Queueing time: mean = 83.227 us, max = 27.147 ms, min = -0.000 s, total = 149.725 ms
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 900 total (1 active), Execution time: mean = 21.602 us, total = 19.442 ms, Queueing time: mean = 52.507 us, max = 499.934 us, min = 5.755 us, total = 47.256 ms
[state-dump] 	MemoryMonitor.CheckIsMemoryUsageAboveThreshold - 720 total (1 active), Execution time: mean = 269.233 us, total = 193.848 ms, Queueing time: mean = 67.359 us, max = 6.752 ms, min = 3.099 us, total = 48.498 ms
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats.OnReplyReceived - 406 total (0 active), Execution time: mean = 17.900 us, total = 7.268 ms, Queueing time: mean = 1.503 ms, max = 9.385 ms, min = 4.159 us, total = 610.383 ms
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 406 total (0 active), Execution time: mean = 1.052 ms, total = 427.182 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.ScheduleAndDispatchTasks - 181 total (1 active), Execution time: mean = 17.847 us, total = 3.230 ms, Queueing time: mean = 52.061 us, max = 176.256 us, min = 9.881 us, total = 9.423 ms
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 180 total (0 active), Execution time: mean = 670.225 us, total = 120.641 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad.HandleRequestImpl - 180 total (0 active), Execution time: mean = 174.540 us, total = 31.417 ms, Queueing time: mean = 76.962 us, max = 148.408 us, min = 21.437 us, total = 13.853 ms
[state-dump] 	NodeManager.deadline_timer.spill_objects_when_over_threshold - 180 total (1 active), Execution time: mean = 3.220 us, total = 579.625 us, Queueing time: mean = 717.834 us, max = 27.461 ms, min = 7.334 us, total = 129.210 ms
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 180 total (1 active), Execution time: mean = 12.081 us, total = 2.175 ms, Queueing time: mean = 710.804 us, max = 27.634 ms, min = 8.304 us, total = 127.945 ms
[state-dump] 	ClientConnection.async_read.ProcessMessageHeader - 162 total (34 active), Execution time: mean = 5.457 us, total = 884.094 us, Queueing time: mean = 1.877 s, max = 121.716 s, min = 15.763 us, total = 304.133 s
[state-dump] 	ClientConnection.async_read.ProcessMessage - 128 total (0 active), Execution time: mean = 972.339 us, total = 124.459 ms, Queueing time: mean = 19.410 us, max = 302.584 us, min = 1.809 us, total = 2.485 ms
[state-dump] 	ClusterResourceManager.ResetRemoteNodeView - 61 total (1 active), Execution time: mean = 10.386 us, total = 633.543 us, Queueing time: mean = 53.230 us, max = 113.390 us, min = 11.211 us, total = 3.247 ms
[state-dump] 	ObjectManager.ObjectAdded - 37 total (0 active), Execution time: mean = 44.608 us, total = 1.651 ms, Queueing time: mean = 21.310 us, max = 110.079 us, min = 5.784 us, total = 788.472 us
[state-dump] 	ObjectManager.ObjectDeleted - 37 total (0 active), Execution time: mean = 19.047 us, total = 704.753 us, Queueing time: mean = 60.787 us, max = 311.924 us, min = 14.729 us, total = 2.249 ms
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 36 total (0 active), Execution time: mean = 997.167 ns, total = 35.898 us, Queueing time: mean = 23.162 us, max = 153.418 us, min = 6.601 us, total = 833.849 us
[state-dump] 	NodeManager.deadline_timer.record_metrics - 36 total (1 active), Execution time: mean = 687.204 us, total = 24.739 ms, Queueing time: mean = 2.901 ms, max = 27.358 ms, min = 26.247 us, total = 104.425 ms
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.CheckAlive.OnReplyReceived - 36 total (0 active), Execution time: mean = 61.311 us, total = 2.207 ms, Queueing time: mean = 301.506 us, max = 9.081 ms, min = 21.601 us, total = 10.854 ms
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.CheckAlive - 36 total (0 active), Execution time: mean = 1.422 ms, total = 51.176 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.GcsCheckAlive - 36 total (1 active), Execution time: mean = 306.334 us, total = 11.028 ms, Queueing time: mean = 3.266 ms, max = 27.580 ms, min = 152.934 us, total = 117.569 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig.HandleRequestImpl - 35 total (0 active), Execution time: mean = 33.161 us, total = 1.161 ms, Queueing time: mean = 43.025 us, max = 358.910 us, min = 7.361 us, total = 1.506 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 35 total (0 active), Execution time: mean = 267.125 us, total = 9.349 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 18 total (1 active), Execution time: mean = 7.071 ms, total = 127.279 ms, Queueing time: mean = 45.817 us, max = 81.548 us, min = 29.210 us, total = 824.711 us
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 13 total (0 active), Execution time: mean = 479.902 us, total = 6.239 ms, Queueing time: mean = 6.426 ms, max = 17.688 ms, min = 53.447 us, total = 83.543 ms
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats.HandleRequestImpl - 12 total (0 active), Execution time: mean = 4.585 ms, total = 55.024 ms, Queueing time: mean = 74.983 us, max = 162.109 us, min = 22.191 us, total = 899.793 us
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 12 total (0 active), Execution time: mean = 1.165 ms, total = 13.977 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch.OnReplyReceived - 12 total (0 active), Execution time: mean = 183.894 us, total = 2.207 ms, Queueing time: mean = 66.448 us, max = 140.626 us, min = 14.886 us, total = 797.378 us
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 12 total (0 active), Execution time: mean = 5.790 ms, total = 69.485 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	RaySyncer.BroadcastMessage - 10 total (0 active), Execution time: mean = 243.284 us, total = 2.433 ms, Queueing time: mean = 508.800 ns, max = 1.052 us, min = 75.000 ns, total = 5.088 us
[state-dump] 	 - 10 total (0 active), Execution time: mean = 1.060 us, total = 10.598 us, Queueing time: mean = 56.659 us, max = 123.718 us, min = 17.545 us, total = 566.591 us
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 7 total (1 active), Execution time: mean = 1.051 s, total = 7.360 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease.HandleRequestImpl - 6 total (0 active), Execution time: mean = 359.743 us, total = 2.158 ms, Queueing time: mean = 39.346 us, max = 59.463 us, min = 25.826 us, total = 236.075 us
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 6 total (0 active), Execution time: mean = 718.247 ms, total = 4.309 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling.OnReplyReceived - 6 total (0 active), Execution time: mean = 229.450 us, total = 1.377 ms, Queueing time: mean = 301.385 us, max = 673.763 us, min = 28.451 us, total = 1.808 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 4 total (0 active), Execution time: mean = 1.466 ms, total = 5.866 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch.OnReplyReceived - 4 total (0 active), Execution time: mean = 129.119 us, total = 516.478 us, Queueing time: mean = 55.842 us, max = 126.774 us, min = 30.884 us, total = 223.369 us
[state-dump] 	WorkerPool.PopWorkerCallback - 4 total (0 active), Execution time: mean = 42.575 us, total = 170.300 us, Queueing time: mean = 14.928 us, max = 18.224 us, min = 7.758 us, total = 59.711 us
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 3 total (1 active, 1 running), Execution time: mean = 1.377 ms, total = 4.132 ms, Queueing time: mean = 16.323 us, max = 26.214 us, min = 22.755 us, total = 48.969 us
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 3 total (1 active), Execution time: mean = 8.681 s, total = 26.042 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs.HandleRequestImpl - 2 total (0 active), Execution time: mean = 685.252 us, total = 1.371 ms, Queueing time: mean = 136.399 us, max = 242.668 us, min = 30.130 us, total = 272.798 us
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 2 total (0 active), Execution time: mean = 1.095 ms, total = 2.190 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 2 total (0 active), Execution time: mean = 238.420 us, total = 476.840 us, Queueing time: mean = 323.839 us, max = 382.201 us, min = 265.477 us, total = 647.678 us
[state-dump] 	RaySyncerRegister - 2 total (0 active), Execution time: mean = 2.406 us, total = 4.812 us, Queueing time: mean = 399.000 ns, max = 725.000 ns, min = 73.000 ns, total = 798.000 ns
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll.OnReplyReceived - 2 total (0 active), Execution time: mean = 249.147 us, total = 498.293 us, Queueing time: mean = 39.880 us, max = 56.731 us, min = 23.029 us, total = 79.760 us
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 2 total (0 active), Execution time: mean = 1.340 ms, total = 2.681 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch.OnReplyReceived - 2 total (0 active), Execution time: mean = 116.618 us, total = 233.237 us, Queueing time: mean = 2.480 ms, max = 4.935 ms, min = 24.523 us, total = 4.959 ms
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.RegisterNode.OnReplyReceived - 1 total (0 active), Execution time: mean = 512.479 us, total = 512.479 us, Queueing time: mean = 35.181 us, max = 35.181 us, min = 35.181 us, total = 35.181 us
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 1 total (0 active), Execution time: mean = 14.970 us, total = 14.970 us, Queueing time: mean = 406.268 us, max = 406.268 us, min = 406.268 us, total = 406.268 us
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), Execution time: mean = 942.762 us, total = 942.762 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 130.863 us, total = 130.863 us, Queueing time: mean = 46.091 us, max = 46.091 us, min = 46.091 us, total = 46.091 us
[state-dump] 	NodeManagerService.grpc_server.ReturnWorker - 1 total (0 active), Execution time: mean = 596.261 us, total = 596.261 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.ReturnWorker.HandleRequestImpl - 1 total (0 active), Execution time: mean = 176.782 us, total = 176.782 us, Queueing time: mean = 19.047 us, max = 19.047 us, min = 19.047 us, total = 19.047 us
[state-dump] 	NodeManagerService.grpc_server.PrepareBundleResources - 1 total (0 active), Execution time: mean = 659.308 us, total = 659.308 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	CoreWorkerService.grpc_client.Exit - 1 total (0 active), Execution time: mean = 1.657 ms, total = 1.657 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalKVGcsService.grpc_client.GetInternalConfig - 1 total (0 active), Execution time: mean = 1.004 ms, total = 1.004 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), Execution time: mean = 48.288 us, total = 48.288 us, Queueing time: mean = 73.934 us, max = 73.934 us, min = 73.934 us, total = 73.934 us
[state-dump] 	CoreWorkerService.grpc_client.Exit.OnReplyReceived - 1 total (0 active), Execution time: mean = 67.247 us, total = 67.247 us, Queueing time: mean = 60.293 us, max = 60.293 us, min = 60.293 us, total = 60.293 us
[state-dump] 	ray::rpc::WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 1 total (0 active), Execution time: mean = 3.719 ms, total = 3.719 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.PrepareBundleResources.HandleRequestImpl - 1 total (0 active), Execution time: mean = 354.575 us, total = 354.575 us, Queueing time: mean = 26.490 us, max = 26.490 us, min = 26.490 us, total = 26.490 us
[state-dump] 	NodeManagerService.grpc_server.CommitBundleResources.HandleRequestImpl - 1 total (0 active), Execution time: mean = 382.745 us, total = 382.745 us, Queueing time: mean = 43.513 us, max = 43.513 us, min = 43.513 us, total = 43.513 us
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), Execution time: mean = 1.494 ms, total = 1.494 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::WorkerInfoGcsService.grpc_client.ReportWorkerFailure.OnReplyReceived - 1 total (0 active), Execution time: mean = 30.591 us, total = 30.591 us, Queueing time: mean = 440.325 us, max = 440.325 us, min = 440.325 us, total = 440.325 us
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.GetAllJobInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 15.904 us, total = 15.904 us, Queueing time: mean = 24.348 us, max = 24.348 us, min = 24.348 us, total = 24.348 us
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), Execution time: mean = 674.721 us, total = 674.721 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), Execution time: mean = 2.987 ms, total = 2.987 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.AddJob.OnReplyReceived - 1 total (0 active), Execution time: mean = 44.604 us, total = 44.604 us, Queueing time: mean = 22.684 us, max = 22.684 us, min = 22.684 us, total = 22.684 us
[state-dump] 	NodeManagerService.grpc_server.CommitBundleResources - 1 total (0 active), Execution time: mean = 549.781 us, total = 549.781 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalKVGcsService.grpc_client.GetInternalConfig.OnReplyReceived - 1 total (0 active), Execution time: mean = 1.034 s, total = 1.034 s, Queueing time: mean = 16.460 us, max = 16.460 us, min = 16.460 us, total = 16.460 us
[state-dump] 	NodeManager.GCTaskFailureReason - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] DebugString() time ms: 2
[state-dump] 
[state-dump] 
[2025-05-04 19:15:53,488 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:58,494 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:15:58,871 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:16:03,857 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:16:08,864 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:16:13,870 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:16:17,467 I 1883226 1883226] (raylet) local_resource_manager.cc:288: Object store memory is idle.
[2025-05-04 19:16:17,667 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:16:17,868 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:16:18,875 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:16:21,869 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:16:21,970 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:16:23,881 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:16:28,886 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:16:33,892 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:16:38,897 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:16:43,902 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:16:48,782 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:16:48,883 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:16:48,907 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:16:52,230 I 1883226 1883259] (raylet) store.cc:564: Plasma store debug dump: 
Current usage: 0.0602915 / 31.4674 GB
- num bytes created total: 258602844
0 pending objects of total size 0MB
- objects spillable: 1
- bytes spillable: 395498
- objects unsealed: 0
- bytes unsealed: 0
- objects in use: 2
- bytes in use: 60291457
- objects evictable: 0
- bytes evictable: 0

- objects created by worker: 2
- bytes created by worker: 60291457
- objects restored: 0
- bytes restored: 0
- objects received: 0
- bytes received: 0
- objects errored: 0
- bytes errored: 0

[2025-05-04 19:16:53,265 I 1883226 1883226] (raylet) node_manager.cc:532: [state-dump] NodeManager:
[state-dump] Node ID: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277
[state-dump] Node name: 10.153.51.195
[state-dump] InitialConfigResources: {object_store_memory: 314674102270000, node:10.153.51.195: 10000, node:__internal_head__: 10000, memory: 634239571970000, CPU: 320000, GPU: 10000, accelerator_type:H100: 10000}
[state-dump] ClusterTaskManager:
[state-dump] ========== Node: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277 =================
[state-dump] Infeasible queue length: 0
[state-dump] Schedule queue length: 0
[state-dump] Dispatch queue length: 0
[state-dump] num_waiting_for_resource: 0
[state-dump] num_waiting_for_plasma_memory: 0
[state-dump] num_waiting_for_remote_node_resources: 0
[state-dump] num_worker_not_started_by_job_config_not_exist: 0
[state-dump] num_worker_not_started_by_registration_timeout: 0
[state-dump] num_tasks_waiting_for_workers: 0
[state-dump] num_cancelled_tasks: 0
[state-dump] cluster_resource_scheduler state: 
[state-dump] Local id: -8542947247730559774 Local resources: {"total":{CPU_group_63639ba0c12292c9677a42d0630201000000: [10000], CPU_group_0_63639ba0c12292c9677a42d0630201000000: [10000], node:__internal_head__: [10000], memory: [634239571970000], GPU: [10000], accelerator_type:H100: [10000], node:10.153.51.195: [10000], object_store_memory: [314674102270000], bundle_group_0_63639ba0c12292c9677a42d0630201000000: [10000000], GPU_group_0_63639ba0c12292c9677a42d0630201000000: [10000], GPU_group_63639ba0c12292c9677a42d0630201000000: [10000], bundle_group_63639ba0c12292c9677a42d0630201000000: [10000000], CPU: [320000]}}, "available": {GPU: [0], GPU_group_0_63639ba0c12292c9677a42d0630201000000: [0], object_store_memory: [314071187700000], node:10.153.51.195: [10000], bundle_group_0_63639ba0c12292c9677a42d0630201000000: [9999990], CPU: [280000], bundle_group_63639ba0c12292c9677a42d0630201000000: [9999990], CPU_group_63639ba0c12292c9677a42d0630201000000: [0], node:__internal_head__: [10000], memory: [634239571970000], CPU_group_0_63639ba0c12292c9677a42d0630201000000: [0], GPU_group_63639ba0c12292c9677a42d0630201000000: [0], accelerator_type:H100: [10000]}}, "labels":{"ray.io/node_id":"526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277",} is_draining: 0 is_idle: 0 Cluster resources: node id: -8542947247730559774{"total":{GPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, node:10.153.51.195: 10000, GPU_group_63639ba0c12292c9677a42d0630201000000: 10000, CPU: 320000, object_store_memory: 314674102270000, CPU_group_63639ba0c12292c9677a42d0630201000000: 10000, bundle_group_63639ba0c12292c9677a42d0630201000000: 10000000, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 10000000, memory: 634239571970000, node:__internal_head__: 10000, CPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, accelerator_type:H100: 10000, GPU: 10000}}, "available": {node:10.153.51.195: 10000, object_store_memory: 314071187700000, CPU: 280000, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 9999990, bundle_group_63639ba0c12292c9677a42d0630201000000: 9999990, node:__internal_head__: 10000, memory: 634239571970000, accelerator_type:H100: 10000}}, "labels":{"ray.io/node_id":"526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277",}, "is_draining": 0, "draining_deadline_timestamp_ms": -1} { "placment group locations": [], "node to bundles": []}
[state-dump] Waiting tasks size: 0
[state-dump] Number of executing tasks: 0
[state-dump] Number of pinned task arguments: 0
[state-dump] Number of total spilled tasks: 0
[state-dump] Number of spilled waiting tasks: 0
[state-dump] Number of spilled unschedulable tasks: 0
[state-dump] Resource usage {
[state-dump]     - (language=PYTHON actor_or_task=WorkerDict.__init__ pid=1886580 worker_id=15629c5564e3fadc61478ea400fccad8e9ac6659227384271beb54b5): {CPU_group_63639ba0c12292c9677a42d0630201000000: 10000, GPU_group_63639ba0c12292c9677a42d0630201000000: 10000, bundle_group_63639ba0c12292c9677a42d0630201000000: 10, CPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, GPU_group_0_63639ba0c12292c9677a42d0630201000000: 10000, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 10}
[state-dump]     - (language=PYTHON actor_or_task=BatchFunctionRewardManager.__init__ pid=1883373 worker_id=35007cacb22a2ab9270518c3a772ef57ac2292cd841da293cf93474f): {CPU: 10000}
[state-dump]     - (language=PYTHON actor_or_task=BatchFunctionRewardManager.__init__ pid=1883367 worker_id=893b844e6104b8bfbe7ab227e5350214387d314adeb85bf2032d74b6): {CPU: 10000}
[state-dump]     - (language=PYTHON actor_or_task=Runner.__init__ pid=1883368 worker_id=2f42c986ad1cd9cfbffa7ff657d795fc9481e7ea1a2c40b84c354d78): {CPU: 10000}
[state-dump]     - (language=PYTHON actor_or_task=WorkerGroupRegisterCenter.__init__ pid=1887223 worker_id=bd8e336aca79943c2e026e1985cfc415588c98dd1f75efc08d91dc1f): {}
[state-dump] }
[state-dump] Backlog Size per scheduling descriptor :{workerId: num backlogs}:
[state-dump] 
[state-dump] Running tasks by scheduling class:
[state-dump] ==================================================
[state-dump] 
[state-dump] ClusterResources:
[state-dump] LocalObjectManager:
[state-dump] - num pinned objects: 2
[state-dump] - pinned objects size: 60291457
[state-dump] - num objects pending restore: 0
[state-dump] - num objects pending spill: 0
[state-dump] - num bytes pending spill: 0
[state-dump] - num bytes currently spilled: 0
[state-dump] - cumulative spill requests: 0
[state-dump] - cumulative restore requests: 0
[state-dump] - spilled objects pending delete: 0
[state-dump] 
[state-dump] ObjectManager:
[state-dump] - num local objects: 2
[state-dump] - num unfulfilled push requests: 0
[state-dump] - num object pull requests: 0
[state-dump] - num chunks received total: 0
[state-dump] - num chunks received failed (all): 0
[state-dump] - num chunks received failed / cancelled: 0
[state-dump] - num chunks received failed / plasma error: 0
[state-dump] Event stats:
[state-dump] Global stats: 5 total (0 active)
[state-dump] Queueing time: mean = 54.412 us, max = 123.478 us, min = 24.924 us, total = 272.062 us
[state-dump] Execution time:  mean = 59.163 us, total = 295.813 us
[state-dump] Event stats:
[state-dump] 	ObjectManager.FreeObjects - 5 total (0 active), Execution time: mean = 59.163 us, total = 295.813 us, Queueing time: mean = 54.412 us, max = 123.478 us, min = 24.924 us, total = 272.062 us
[state-dump] PushManager:
[state-dump] - num pushes in flight: 0
[state-dump] - num chunks in flight: 0
[state-dump] - num chunks remaining: 0
[state-dump] - max chunks allowed: 409
[state-dump] OwnershipBasedObjectDirectory:
[state-dump] - num listeners: 0
[state-dump] - cumulative location updates: 0
[state-dump] - num location updates per second: 0.000
[state-dump] - num location lookups per second: 0.000
[state-dump] - num locations added per second: 0.400
[state-dump] - num locations removed per second: 0.000
[state-dump] BufferPool:
[state-dump] - create buffer state map size: 0
[state-dump] PullManager:
[state-dump] - num bytes available for pulled objects: 31407118770
[state-dump] - num bytes being pulled (all): 0
[state-dump] - num bytes being pulled / pinned: 0
[state-dump] - get request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - wait request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - task request bundles: BundlePullRequestQueue{0 total, 0 active, 0 inactive, 0 unpullable}
[state-dump] - first get request bundle: N/A
[state-dump] - first wait request bundle: N/A
[state-dump] - first task request bundle: N/A
[state-dump] - num objects queued: 0
[state-dump] - num objects actively pulled (all): 0
[state-dump] - num objects actively pulled / pinned: 0
[state-dump] - num bundles being pulled: 0
[state-dump] - num pull retries: 0
[state-dump] - max timeout seconds: 0
[state-dump] - max timeout request is already processed. No entry.
[state-dump] 
[state-dump] WorkerPool:
[state-dump] - registered jobs: 1
[state-dump] - process_failed_job_config_missing: 0
[state-dump] - process_failed_rate_limited: 0
[state-dump] - process_failed_pending_registration: 0
[state-dump] - process_failed_runtime_env_setup_failed: 0
[state-dump] - num JAVA workers: 0
[state-dump] - num JAVA drivers: 0
[state-dump] - num JAVA pending start requests: 0
[state-dump] - num JAVA pending registration requests: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num PYTHON workers: 33
[state-dump] - num PYTHON drivers: 1
[state-dump] - num PYTHON pending start requests: 0
[state-dump] - num PYTHON pending registration requests: 0
[state-dump] - num object spill callbacks queued: 0
[state-dump] - num object restore queued: 0
[state-dump] - num util functions queued: 0
[state-dump] - num idle workers: 28
[state-dump] TaskDependencyManager:
[state-dump] - task deps map size: 0
[state-dump] - get req map size: 0
[state-dump] - wait req map size: 0
[state-dump] - local objects map size: 2
[state-dump] WaitManager:
[state-dump] - num active wait requests: 0
[state-dump] Subscriber:
[state-dump] Channel WORKER_OBJECT_EVICTION
[state-dump] - cumulative subscribe requests: 11
[state-dump] - cumulative unsubscribe requests: 9
[state-dump] - active subscribed publishers: 1
[state-dump] - cumulative published messages: 9
[state-dump] - cumulative processed messages: 9
[state-dump] Channel WORKER_REF_REMOVED_CHANNEL
[state-dump] - cumulative subscribe requests: 0
[state-dump] - cumulative unsubscribe requests: 0
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] Channel WORKER_OBJECT_LOCATIONS_CHANNEL
[state-dump] - cumulative subscribe requests: 13
[state-dump] - cumulative unsubscribe requests: 13
[state-dump] - active subscribed publishers: 0
[state-dump] - cumulative published messages: 0
[state-dump] - cumulative processed messages: 0
[state-dump] num async plasma notifications: 0
[state-dump] Remote node managers: 
[state-dump] Event stats:
[state-dump] Global stats: 28967 total (49 active)
[state-dump] Queueing time: mean = 25.110 ms, max = 178.024 s, min = -0.000 s, total = 727.362 s
[state-dump] Execution time:  mean = 8.768 ms, total = 253.991 s
[state-dump] Event stats:
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog - 8087 total (0 active), Execution time: mean = 450.168 us, total = 3.641 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.ReportWorkerBacklog.HandleRequestImpl - 8087 total (0 active), Execution time: mean = 37.607 us, total = 304.126 ms, Queueing time: mean = 120.008 us, max = 255.220 ms, min = 2.239 us, total = 970.503 ms
[state-dump] 	ObjectManager.UpdateAvailableMemory - 2394 total (0 active), Execution time: mean = 5.377 us, total = 12.872 ms, Queueing time: mean = 42.831 us, max = 503.560 us, min = 2.861 us, total = 102.537 ms
[state-dump] 	NodeManager.CheckGC - 2394 total (1 active), Execution time: mean = 3.759 us, total = 8.999 ms, Queueing time: mean = 258.788 us, max = 381.789 ms, min = 4.308 us, total = 619.539 ms
[state-dump] 	RaySyncer.OnDemandBroadcasting - 2394 total (1 active), Execution time: mean = 14.263 us, total = 34.145 ms, Queueing time: mean = 248.858 us, max = 381.796 ms, min = -0.000 s, total = 595.766 ms
[state-dump] 	RayletWorkerPool.deadline_timer.kill_idle_workers - 1198 total (1 active), Execution time: mean = 20.738 us, total = 24.844 ms, Queueing time: mean = 337.721 us, max = 342.140 ms, min = 4.377 us, total = 404.590 ms
[state-dump] 	MemoryMonitor.CheckIsMemoryUsageAboveThreshold - 958 total (1 active), Execution time: mean = 265.394 us, total = 254.248 ms, Queueing time: mean = 431.791 us, max = 355.741 ms, min = 3.099 us, total = 413.656 ms
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats.OnReplyReceived - 542 total (0 active), Execution time: mean = 17.996 us, total = 9.754 ms, Queueing time: mean = 1.446 ms, max = 9.385 ms, min = 4.159 us, total = 783.884 ms
[state-dump] 	CoreWorkerService.grpc_client.GetCoreWorkerStats - 542 total (0 active), Execution time: mean = 1.017 ms, total = 551.169 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.ScheduleAndDispatchTasks - 241 total (1 active), Execution time: mean = 17.669 us, total = 4.258 ms, Queueing time: mean = 49.504 us, max = 176.256 us, min = 8.579 us, total = 11.931 ms
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad - 240 total (0 active), Execution time: mean = 1.345 ms, total = 322.848 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.GetResourceLoad.HandleRequestImpl - 240 total (0 active), Execution time: mean = 171.625 us, total = 41.190 ms, Queueing time: mean = 776.166 us, max = 169.246 ms, min = 14.011 us, total = 186.280 ms
[state-dump] 	NodeManager.deadline_timer.spill_objects_when_over_threshold - 240 total (1 active), Execution time: mean = 3.142 us, total = 754.179 us, Queueing time: mean = 2.567 ms, max = 388.775 ms, min = 2.881 us, total = 616.139 ms
[state-dump] 	NodeManager.deadline_timer.flush_free_objects - 240 total (1 active), Execution time: mean = 14.952 us, total = 3.589 ms, Queueing time: mean = 2.557 ms, max = 388.783 ms, min = 2.459 us, total = 613.762 ms
[state-dump] 	ClientConnection.async_read.ProcessMessageHeader - 185 total (34 active), Execution time: mean = 6.164 us, total = 1.140 ms, Queueing time: mean = 3.896 s, max = 178.024 s, min = 15.763 us, total = 720.726 s
[state-dump] 	ClientConnection.async_read.ProcessMessage - 151 total (0 active), Execution time: mean = 844.952 us, total = 127.588 ms, Queueing time: mean = 18.280 us, max = 302.584 us, min = 1.809 us, total = 2.760 ms
[state-dump] 	ClusterResourceManager.ResetRemoteNodeView - 81 total (1 active), Execution time: mean = 10.628 us, total = 860.874 us, Queueing time: mean = 48.890 us, max = 113.390 us, min = 11.211 us, total = 3.960 ms
[state-dump] 	NodeManager.GcsCheckAlive - 48 total (1 active), Execution time: mean = 298.307 us, total = 14.319 ms, Queueing time: mean = 12.522 ms, max = 388.725 ms, min = 7.083 us, total = 601.066 ms
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.CheckAlive - 48 total (0 active), Execution time: mean = 1.318 ms, total = 63.266 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.record_metrics - 48 total (1 active), Execution time: mean = 669.317 us, total = 32.127 ms, Queueing time: mean = 12.168 ms, max = 388.210 ms, min = 13.482 us, total = 584.062 ms
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.CheckAlive.OnReplyReceived - 48 total (0 active), Execution time: mean = 58.174 us, total = 2.792 ms, Queueing time: mean = 233.255 us, max = 9.081 ms, min = 12.905 us, total = 11.196 ms
[state-dump] 	ObjectManager.ObjectAdded - 46 total (0 active), Execution time: mean = 91.617 us, total = 4.214 ms, Queueing time: mean = 27.319 us, max = 113.218 us, min = 5.784 us, total = 1.257 ms
[state-dump] 	ObjectManager.ObjectDeleted - 44 total (0 active), Execution time: mean = 35.199 us, total = 1.549 ms, Queueing time: mean = 75.765 us, max = 338.812 us, min = 14.729 us, total = 3.334 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch.OnReplyReceived - 40 total (0 active), Execution time: mean = 151.596 us, total = 6.064 ms, Queueing time: mean = 118.824 us, max = 859.559 us, min = 11.682 us, total = 4.753 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubCommandBatch - 40 total (0 active), Execution time: mean = 998.943 us, total = 39.958 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ClientConnection.async_write.DoAsyncWrites - 36 total (0 active), Execution time: mean = 997.167 ns, total = 35.898 us, Queueing time: mean = 23.162 us, max = 153.418 us, min = 6.601 us, total = 833.849 us
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig.HandleRequestImpl - 35 total (0 active), Execution time: mean = 33.161 us, total = 1.161 ms, Queueing time: mean = 43.025 us, max = 358.910 us, min = 7.361 us, total = 1.506 ms
[state-dump] 	NodeManagerService.grpc_server.GetSystemConfig - 35 total (0 active), Execution time: mean = 267.125 us, total = 9.349 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManager.deadline_timer.debug_state_dump - 24 total (1 active), Execution time: mean = 25.627 ms, total = 615.057 ms, Queueing time: mean = 43.479 us, max = 81.548 us, min = 24.071 us, total = 1.043 ms
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling - 23 total (1 active), Execution time: mean = 9.401 s, total = 216.225 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	CoreWorkerService.grpc_client.PubsubLongPolling.OnReplyReceived - 22 total (0 active), Execution time: mean = 325.187 us, total = 7.154 ms, Queueing time: mean = 172.599 us, max = 714.059 us, min = 13.406 us, total = 3.797 ms
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch - 20 total (0 active), Execution time: mean = 1.055 ms, total = 21.091 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	CoreWorkerService.grpc_client.UpdateObjectLocationBatch.OnReplyReceived - 20 total (0 active), Execution time: mean = 64.477 us, total = 1.290 ms, Queueing time: mean = 40.482 us, max = 186.976 us, min = 8.164 us, total = 809.644 us
[state-dump] 	 - 18 total (0 active), Execution time: mean = 955.222 ns, total = 17.194 us, Queueing time: mean = 42.383 us, max = 123.718 us, min = 8.990 us, total = 762.896 us
[state-dump] 	RaySyncer.BroadcastMessage - 18 total (0 active), Execution time: mean = 239.781 us, total = 4.316 ms, Queueing time: mean = 532.889 ns, max = 1.052 us, min = 75.000 ns, total = 9.592 us
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats - 16 total (0 active), Execution time: mean = 5.565 ms, total = 89.035 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.GetNodeStats.HandleRequestImpl - 16 total (0 active), Execution time: mean = 4.394 ms, total = 70.298 ms, Queueing time: mean = 75.342 us, max = 162.109 us, min = 22.191 us, total = 1.205 ms
[state-dump] 	PeriodicalRunner.RunFnPeriodically - 13 total (0 active), Execution time: mean = 479.902 us, total = 6.239 ms, Queueing time: mean = 6.426 ms, max = 17.688 ms, min = 53.447 us, total = 83.543 ms
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs.HandleRequestImpl - 11 total (0 active), Execution time: mean = 433.894 us, total = 4.773 ms, Queueing time: mean = 45.022 us, max = 242.668 us, min = 14.686 us, total = 495.239 us
[state-dump] 	NodeManagerService.grpc_server.PinObjectIDs - 11 total (0 active), Execution time: mean = 751.786 us, total = 8.270 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	Subscriber.HandlePublishedMessage_WORKER_OBJECT_EVICTION - 9 total (0 active), Execution time: mean = 115.472 us, total = 1.039 ms, Queueing time: mean = 406.202 us, max = 704.425 us, min = 105.329 us, total = 3.656 ms
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease.HandleRequestImpl - 6 total (0 active), Execution time: mean = 359.743 us, total = 2.158 ms, Queueing time: mean = 39.346 us, max = 59.463 us, min = 25.826 us, total = 236.075 us
[state-dump] 	NodeManagerService.grpc_server.RequestWorkerLease - 6 total (0 active), Execution time: mean = 718.247 ms, total = 4.309 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete - 5 total (0 active), Execution time: mean = 975.770 us, total = 4.879 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	CoreWorkerService.grpc_client.DirectActorCallArgWaitComplete.OnReplyReceived - 5 total (0 active), Execution time: mean = 29.743 us, total = 148.714 us, Queueing time: mean = 102.925 us, max = 295.290 us, min = 11.556 us, total = 514.623 us
[state-dump] 	NodeManager.deadline_timer.print_event_loop_stats - 4 total (1 active, 1 running), Execution time: mean = 1.818 ms, total = 7.271 ms, Queueing time: mean = 14.293 us, max = 26.214 us, min = 8.204 us, total = 57.173 us
[state-dump] 	WorkerPool.PopWorkerCallback - 4 total (0 active), Execution time: mean = 42.575 us, total = 170.300 us, Queueing time: mean = 14.928 us, max = 18.224 us, min = 7.758 us, total = 59.711 us
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll - 3 total (1 active), Execution time: mean = 8.681 s, total = 26.042 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch - 2 total (0 active), Execution time: mean = 1.340 ms, total = 2.681 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberPoll.OnReplyReceived - 2 total (0 active), Execution time: mean = 249.147 us, total = 498.293 us, Queueing time: mean = 39.880 us, max = 56.731 us, min = 23.029 us, total = 79.760 us
[state-dump] 	ray::rpc::InternalPubSubGcsService.grpc_client.GcsSubscriberCommandBatch.OnReplyReceived - 2 total (0 active), Execution time: mean = 116.618 us, total = 233.237 us, Queueing time: mean = 2.480 ms, max = 4.935 ms, min = 24.523 us, total = 4.959 ms
[state-dump] 	RaySyncerRegister - 2 total (0 active), Execution time: mean = 2.406 us, total = 4.812 us, Queueing time: mean = 399.000 ns, max = 725.000 ns, min = 73.000 ns, total = 798.000 ns
[state-dump] 	NodeManagerService.grpc_server.ReturnWorker - 1 total (0 active), Execution time: mean = 596.261 us, total = 596.261 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.RegisterNode.OnReplyReceived - 1 total (0 active), Execution time: mean = 512.479 us, total = 512.479 us, Queueing time: mean = 35.181 us, max = 35.181 us, min = 35.181 us, total = 35.181 us
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.GetAllJobInfo - 1 total (0 active), Execution time: mean = 942.762 us, total = 942.762 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_WORKER_DELTA_CHANNEL - 1 total (0 active), Execution time: mean = 14.970 us, total = 14.970 us, Queueing time: mean = 406.268 us, max = 406.268 us, min = 406.268 us, total = 406.268 us
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 130.863 us, total = 130.863 us, Queueing time: mean = 46.091 us, max = 46.091 us, min = 46.091 us, total = 46.091 us
[state-dump] 	NodeManagerService.grpc_server.ReturnWorker.HandleRequestImpl - 1 total (0 active), Execution time: mean = 176.782 us, total = 176.782 us, Queueing time: mean = 19.047 us, max = 19.047 us, min = 19.047 us, total = 19.047 us
[state-dump] 	NodeManagerService.grpc_server.PrepareBundleResources - 1 total (0 active), Execution time: mean = 659.308 us, total = 659.308 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	CoreWorkerService.grpc_client.Exit - 1 total (0 active), Execution time: mean = 1.657 ms, total = 1.657 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalKVGcsService.grpc_client.GetInternalConfig - 1 total (0 active), Execution time: mean = 1.004 ms, total = 1.004 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	Subscriber.HandlePublishedMessage_GCS_JOB_CHANNEL - 1 total (0 active), Execution time: mean = 48.288 us, total = 48.288 us, Queueing time: mean = 73.934 us, max = 73.934 us, min = 73.934 us, total = 73.934 us
[state-dump] 	CoreWorkerService.grpc_client.Exit.OnReplyReceived - 1 total (0 active), Execution time: mean = 67.247 us, total = 67.247 us, Queueing time: mean = 60.293 us, max = 60.293 us, min = 60.293 us, total = 60.293 us
[state-dump] 	ray::rpc::WorkerInfoGcsService.grpc_client.ReportWorkerFailure - 1 total (0 active), Execution time: mean = 3.719 ms, total = 3.719 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	NodeManagerService.grpc_server.PrepareBundleResources.HandleRequestImpl - 1 total (0 active), Execution time: mean = 354.575 us, total = 354.575 us, Queueing time: mean = 26.490 us, max = 26.490 us, min = 26.490 us, total = 26.490 us
[state-dump] 	NodeManagerService.grpc_server.CommitBundleResources.HandleRequestImpl - 1 total (0 active), Execution time: mean = 382.745 us, total = 382.745 us, Queueing time: mean = 43.513 us, max = 43.513 us, min = 43.513 us, total = 43.513 us
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.GetAllNodeInfo - 1 total (0 active), Execution time: mean = 1.494 ms, total = 1.494 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::WorkerInfoGcsService.grpc_client.ReportWorkerFailure.OnReplyReceived - 1 total (0 active), Execution time: mean = 30.591 us, total = 30.591 us, Queueing time: mean = 440.325 us, max = 440.325 us, min = 440.325 us, total = 440.325 us
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.GetAllJobInfo.OnReplyReceived - 1 total (0 active), Execution time: mean = 15.904 us, total = 15.904 us, Queueing time: mean = 24.348 us, max = 24.348 us, min = 24.348 us, total = 24.348 us
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.AddJob - 1 total (0 active), Execution time: mean = 674.721 us, total = 674.721 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::NodeInfoGcsService.grpc_client.RegisterNode - 1 total (0 active), Execution time: mean = 2.987 ms, total = 2.987 ms, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::JobInfoGcsService.grpc_client.AddJob.OnReplyReceived - 1 total (0 active), Execution time: mean = 44.604 us, total = 44.604 us, Queueing time: mean = 22.684 us, max = 22.684 us, min = 22.684 us, total = 22.684 us
[state-dump] 	NodeManagerService.grpc_server.CommitBundleResources - 1 total (0 active), Execution time: mean = 549.781 us, total = 549.781 us, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] 	ray::rpc::InternalKVGcsService.grpc_client.GetInternalConfig.OnReplyReceived - 1 total (0 active), Execution time: mean = 1.034 s, total = 1.034 s, Queueing time: mean = 16.460 us, max = 16.460 us, min = 16.460 us, total = 16.460 us
[state-dump] 	NodeManager.GCTaskFailureReason - 1 total (1 active), Execution time: mean = 0.000 s, total = 0.000 s, Queueing time: mean = 0.000 s, max = -0.000 s, min = 9223372036.855 s, total = 0.000 s
[state-dump] DebugString() time ms: 1
[state-dump] 
[state-dump] 
[2025-05-04 19:16:53,914 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:16:58,921 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:17:03,927 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:17:08,934 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:17:13,940 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:17:18,945 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:17:23,953 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:17:28,959 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:17:33,965 W 1883226 1883226] (raylet) memory_monitor.cc:198: Got negative used memory for cgroup -1, setting it to zero
[2025-05-04 19:17:34,215 I 1883226 1883226] (raylet) memory_monitor.cc:89: Node memory usage above threshold, used: 128247177216, threshold_bytes: 128114286592, total bytes: 134857150464, threshold fraction: 0.95
[2025-05-04 19:17:34,220 W 1883226 1883226] (raylet) memory_monitor.cc:299:  file not found: /proc/1/smaps_rollup
[2025-05-04 19:17:34,223 W 1883226 1883226] (raylet) memory_monitor.cc:325: Got zero used memory for smap file /proc/2/smaps_rollup
[2025-05-04 19:17:35,423 I 1883226 1883226] (raylet) worker_killing_policy_group_by_owner.cc:91: Sorted list of tasks based on the policy:
Tasks (retriable: 1) (parent task id: 16310a0f0a45af5ce7d7ad62079eb75499575d8201000000) (Earliest assigned time: 2025-05-04T17:13:17.74000995+00:00):
Task assigned time 2025-05-04T17:13:17.74000995+00:00 worker id 835cfccc2147d7417baed2e09d4ca9b8e04d3699531b742bc17574c0 memory used 57180160 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {bundle_group_63639ba0c12292c9677a42d0630201000000: 0.001, }, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.util.placement_group, class_name=, function_name=_export_bundle_reservation_check_method_if_needed.<locals>.bundle_reservation_check_func, function_hash=5583db5feee74ff3b285b65a611fc526}, task_id=1bc699a9d72a50d6ad0fc819425c16628dcad2fdffffffff, task_name=bundle_reservation_check_func, job_id=01000000, num_args=2, num_returns=1, max_retries=3, depth=2, attempt_number=0
Tasks (retriable: 0) (parent task id: NIL_ID) (Earliest assigned time: 1970-01-01T00:00:00+00:00):
Task assigned time 1970-01-01T00:00:00+00:00 worker id b0016cebf35442a3767ad611841756519747fd947def35cad219a717 memory used 41345024 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id a78e0951b046348e53e0656c6a8387cf4080e269f90e0fc110261847 memory used 41345024 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 2025-05-04T17:13:19.9859872+00:00 worker id 15629c5564e3fadc61478ea400fccad8e9ac6659227384271beb54b5 memory used 91836522496 task spec Type=ACTOR_CREATION_TASK, Language=PYTHON, Resources: {CPU_group_63639ba0c12292c9677a42d0630201000000: 1, GPU_group_0_63639ba0c12292c9677a42d0630201000000: 1, GPU_group_63639ba0c12292c9677a42d0630201000000: 1, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 0.001, bundle_group_63639ba0c12292c9677a42d0630201000000: 0.001, CPU_group_0_63639ba0c12292c9677a42d0630201000000: 1, }, function_descriptor={type=PythonFunctionDescriptor, module_name=verl.single_controller.ray.base, class_name=create_colocated_worker_cls.<locals>.WorkerDict, function_name=__init__, function_hash=c9fcaae4a0634132bed0ee44930ddbab}, task_id=ffffffffffffffff119135d41f3c0a01ae1883dd01000000, task_name=2paz6NWorkerDict_0:0:WorkerDict.__init__, job_id=01000000, num_args=0, num_returns=1, max_retries=0, depth=2, attempt_number=0, actor_creation_task_spec={actor_id=119135d41f3c0a01ae1883dd01000000, max_restarts=0, max_concurrency=1, is_asyncio_actor=0, is_detached=0}, runtime_env_hash=-1775124242, eager_install=1, setup_timeout_seconds=600
Task assigned time 1970-01-01T00:00:00+00:00 worker id fc915d7501a00e73ef81f10c5b9ec92328923a7784136794e719f5b4 memory used 41320448 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 9d9fbadc43e0bc9e7407be21dd19757d66f897a1209292b05d9d0825 memory used 41336832 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 2f2bf48676361753abc6551d58e9429195afab486ab41601e6944849 memory used 41345024 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 7ee73985527711d782888c62e5d5d82ab3a80404540021d89384befe memory used 41340928 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 2025-05-04T17:13:12.729494328+00:00 worker id 35007cacb22a2ab9270518c3a772ef57ac2292cd841da293cf93474f memory used 448798720 task spec Type=ACTOR_CREATION_TASK, Language=PYTHON, Resources: {CPU: 1, }, function_descriptor={type=PythonFunctionDescriptor, module_name=verl.workers.reward.function, class_name=BatchFunctionRewardManager, function_name=__init__, function_hash=1a7763f6398e4b55b5ba9fedea414ed6}, task_id=ffffffffffffffff9a34dc5333bf4e603e04387101000000, task_name=BatchFunctionRewardManager.__init__, job_id=01000000, num_args=4, num_returns=1, max_retries=0, depth=2, attempt_number=0, actor_creation_task_spec={actor_id=9a34dc5333bf4e603e04387101000000, max_restarts=0, max_concurrency=1, is_asyncio_actor=0, is_detached=0}
Task assigned time 1970-01-01T00:00:00+00:00 worker id 84b1d19ee1292292dbf0cd223cca2b6056113572d81d49d06d86303a memory used 41312256 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 2d71ca0bcd8fdc19f38133927a911caf8b7cca9a4b84e787ea090ea4 memory used 41328640 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 628fb177ac05b590985fa790bc236a8b104c7e7dfcf214cf700c43b0 memory used 41320448 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0

Task should be retried? 0
[2025-05-04 19:17:35,423 I 1883226 1883226] (raylet) node_manager.cc:3057: Killing worker with task Type=NORMAL_TASK, Language=PYTHON, Resources: {bundle_group_63639ba0c12292c9677a42d0630201000000: 0.001, }, function_descriptor={type=PythonFunctionDescriptor, module_name=ray.util.placement_group, class_name=, function_name=_export_bundle_reservation_check_method_if_needed.<locals>.bundle_reservation_check_func, function_hash=5583db5feee74ff3b285b65a611fc526}, task_id=1bc699a9d72a50d6ad0fc819425c16628dcad2fdffffffff, task_name=bundle_reservation_check_func, job_id=01000000, num_args=2, num_returns=1, max_retries=3, depth=2, attempt_number=0

Memory on the node (IP: 10.153.51.195, ID: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277) where the task (task ID: NIL_ID, name=bundle_reservation_check_func, pid=1883366, memory used=0.05GB) was running was 119.44GB / 125.60GB (0.950985), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 835cfccc2147d7417baed2e09d4ca9b8e04d3699531b742bc17574c0) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.153.51.195`. To see the logs of the worker, use `ray logs worker-835cfccc2147d7417baed2e09d4ca9b8e04d3699531b742bc17574c0*out -ip 10.153.51.195. Top 10 memory users:
PID	MEM(GB)	COMMAND
1886580	85.53	ray::WorkerDict
1687895	0.92	/home/wiss/liao/.vscode-server/cli/servers/Stable-ddc367ed5c8936efe395cffeec279b04ffd7db78/server/no...
1687772	0.86	/home/wiss/liao/.vscode-server/cli/servers/Stable-ddc367ed5c8936efe395cffeec279b04ffd7db78/server/no...
1882418	0.49	python3 -m verl.trainer.main_tools config=examples/config_tools.yaml data.train_files=BLINK-Benchmar...
1883367	0.49	ray::BatchFunctionRewardManager
1687787	0.48	/home/wiss/liao/.vscode-server/cli/servers/Stable-ddc367ed5c8936efe395cffeec279b04ffd7db78/server/no...
1883373	0.42	ray::BatchFunctionRewardManager
1883368	0.22	ray::Runner.run
1893097	0.18	ray::Runner.run
1893098	0.18	ray::Runner.run

Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[2025-05-04 19:17:35,423 I 1883226 1883226] (raylet) node_manager.cc:1549: NodeManager::DisconnectClient, disconnect_type=4, has creation task exception = false
[2025-05-04 19:17:35,426 I 1883226 1883226] (raylet) node_manager.cc:1549: NodeManager::DisconnectClient, disconnect_type=0, has creation task exception = false
[2025-05-04 19:17:35,426 I 1883226 1883226] (raylet) node_manager.cc:1563: Ignoring client disconnect because the client has already been disconnected.
[2025-05-04 19:17:35,526 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:17:35,675 I 1883226 1883226] (raylet) node_manager.cc:3015: Worker evicted and process killed to reclaim memory. worker pid: 1883366 worker_id=835cfccc2147d7417baed2e09d4ca9b8e04d3699531b742bc17574c0 task_id=NIL_ID
[2025-05-04 19:17:36,565 I 1883226 1883226] (raylet) worker_killing_policy_group_by_owner.cc:91: Sorted list of tasks based on the policy:
Tasks (retriable: 0) (parent task id: NIL_ID) (Earliest assigned time: 1970-01-01T00:00:00+00:00):
Task assigned time 1970-01-01T00:00:00+00:00 worker id b0016cebf35442a3767ad611841756519747fd947def35cad219a717 memory used 41345024 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id a78e0951b046348e53e0656c6a8387cf4080e269f90e0fc110261847 memory used 41345024 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 2025-05-04T17:13:19.9859872+00:00 worker id 15629c5564e3fadc61478ea400fccad8e9ac6659227384271beb54b5 memory used 92104896512 task spec Type=ACTOR_CREATION_TASK, Language=PYTHON, Resources: {CPU_group_63639ba0c12292c9677a42d0630201000000: 1, GPU_group_0_63639ba0c12292c9677a42d0630201000000: 1, GPU_group_63639ba0c12292c9677a42d0630201000000: 1, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 0.001, bundle_group_63639ba0c12292c9677a42d0630201000000: 0.001, CPU_group_0_63639ba0c12292c9677a42d0630201000000: 1, }, function_descriptor={type=PythonFunctionDescriptor, module_name=verl.single_controller.ray.base, class_name=create_colocated_worker_cls.<locals>.WorkerDict, function_name=__init__, function_hash=c9fcaae4a0634132bed0ee44930ddbab}, task_id=ffffffffffffffff119135d41f3c0a01ae1883dd01000000, task_name=2paz6NWorkerDict_0:0:WorkerDict.__init__, job_id=01000000, num_args=0, num_returns=1, max_retries=0, depth=2, attempt_number=0, actor_creation_task_spec={actor_id=119135d41f3c0a01ae1883dd01000000, max_restarts=0, max_concurrency=1, is_asyncio_actor=0, is_detached=0}, runtime_env_hash=-1775124242, eager_install=1, setup_timeout_seconds=600
Task assigned time 1970-01-01T00:00:00+00:00 worker id fc915d7501a00e73ef81f10c5b9ec92328923a7784136794e719f5b4 memory used 41320448 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 9d9fbadc43e0bc9e7407be21dd19757d66f897a1209292b05d9d0825 memory used 41336832 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 2f2bf48676361753abc6551d58e9429195afab486ab41601e6944849 memory used 41345024 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 7ee73985527711d782888c62e5d5d82ab3a80404540021d89384befe memory used 41340928 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 2025-05-04T17:13:12.729494328+00:00 worker id 35007cacb22a2ab9270518c3a772ef57ac2292cd841da293cf93474f memory used 448798720 task spec Type=ACTOR_CREATION_TASK, Language=PYTHON, Resources: {CPU: 1, }, function_descriptor={type=PythonFunctionDescriptor, module_name=verl.workers.reward.function, class_name=BatchFunctionRewardManager, function_name=__init__, function_hash=1a7763f6398e4b55b5ba9fedea414ed6}, task_id=ffffffffffffffff9a34dc5333bf4e603e04387101000000, task_name=BatchFunctionRewardManager.__init__, job_id=01000000, num_args=4, num_returns=1, max_retries=0, depth=2, attempt_number=0, actor_creation_task_spec={actor_id=9a34dc5333bf4e603e04387101000000, max_restarts=0, max_concurrency=1, is_asyncio_actor=0, is_detached=0}
Task assigned time 1970-01-01T00:00:00+00:00 worker id 84b1d19ee1292292dbf0cd223cca2b6056113572d81d49d06d86303a memory used 41312256 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 2d71ca0bcd8fdc19f38133927a911caf8b7cca9a4b84e787ea090ea4 memory used 41328640 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 628fb177ac05b590985fa790bc236a8b104c7e7dfcf214cf700c43b0 memory used 41320448 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0

Task should be retried? 0
[2025-05-04 19:17:36,565 I 1883226 1883226] (raylet) node_manager.cc:3057: Killing worker with task Type=ACTOR_CREATION_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=PythonFunctionDescriptor, module_name=verl.single_controller.base.register_center.ray, class_name=WorkerGroupRegisterCenter, function_name=__init__, function_hash=d126ef18914448e2956de935afd630b8}, task_id=ffffffffffffffff7bb90851443339650f004cf601000000, task_name=2paz6N_register_center:WorkerGroupRegisterCenter.__init__, job_id=01000000, num_args=2, num_returns=1, max_retries=0, depth=3, attempt_number=0, actor_creation_task_spec={actor_id=7bb90851443339650f004cf601000000, max_restarts=0, max_concurrency=1, is_asyncio_actor=0, is_detached=0}, runtime_env_hash=-1775124242, eager_install=1, setup_timeout_seconds=600

Memory on the node (IP: 10.153.51.195, ID: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277) where the task (actor ID: 7bb90851443339650f004cf601000000, name=2paz6N_register_center:WorkerGroupRegisterCenter.__init__, pid=1887223, memory used=0.05GB) was running was 119.42GB / 125.60GB (0.950821), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: bd8e336aca79943c2e026e1985cfc415588c98dd1f75efc08d91dc1f) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.153.51.195`. To see the logs of the worker, use `ray logs worker-bd8e336aca79943c2e026e1985cfc415588c98dd1f75efc08d91dc1f*out -ip 10.153.51.195. Top 10 memory users:
PID	MEM(GB)	COMMAND
1886580	85.78	ray::WorkerDict
1687895	0.92	/home/wiss/liao/.vscode-server/cli/servers/Stable-ddc367ed5c8936efe395cffeec279b04ffd7db78/server/no...
1687772	0.86	/home/wiss/liao/.vscode-server/cli/servers/Stable-ddc367ed5c8936efe395cffeec279b04ffd7db78/server/no...
1882418	0.49	python3 -m verl.trainer.main_tools config=examples/config_tools.yaml data.train_files=BLINK-Benchmar...
1883367	0.49	ray::BatchFunctionRewardManager
1687787	0.48	/home/wiss/liao/.vscode-server/cli/servers/Stable-ddc367ed5c8936efe395cffeec279b04ffd7db78/server/no...
1883373	0.42	ray::BatchFunctionRewardManager
1883368	0.20	ray::Runner.run
1893097	0.18	ray::Runner.run
1893098	0.18	ray::Runner.run

Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[2025-05-04 19:17:36,607 I 1883226 1883226] (raylet) node_manager.cc:1549: NodeManager::DisconnectClient, disconnect_type=4, has creation task exception = false
[2025-05-04 19:17:36,609 I 1883226 1883226] (raylet) node_manager.cc:1549: NodeManager::DisconnectClient, disconnect_type=0, has creation task exception = false
[2025-05-04 19:17:36,609 I 1883226 1883226] (raylet) node_manager.cc:1563: Ignoring client disconnect because the client has already been disconnected.
[2025-05-04 19:17:36,610 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:17:36,859 I 1883226 1883226] (raylet) node_manager.cc:3015: Worker evicted and process killed to reclaim memory. worker pid: 1887223 worker_id=bd8e336aca79943c2e026e1985cfc415588c98dd1f75efc08d91dc1f task_id=ffffffffffffffff7bb90851443339650f004cf601000000
[2025-05-04 19:17:37,714 I 1883226 1883226] (raylet) worker_killing_policy_group_by_owner.cc:91: Sorted list of tasks based on the policy:
Tasks (retriable: 0) (parent task id: NIL_ID) (Earliest assigned time: 1970-01-01T00:00:00+00:00):
Task assigned time 1970-01-01T00:00:00+00:00 worker id b0016cebf35442a3767ad611841756519747fd947def35cad219a717 memory used 41345024 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id a78e0951b046348e53e0656c6a8387cf4080e269f90e0fc110261847 memory used 41345024 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 2025-05-04T17:13:19.9859872+00:00 worker id 15629c5564e3fadc61478ea400fccad8e9ac6659227384271beb54b5 memory used 92106022912 task spec Type=ACTOR_CREATION_TASK, Language=PYTHON, Resources: {CPU_group_63639ba0c12292c9677a42d0630201000000: 1, GPU_group_0_63639ba0c12292c9677a42d0630201000000: 1, GPU_group_63639ba0c12292c9677a42d0630201000000: 1, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 0.001, bundle_group_63639ba0c12292c9677a42d0630201000000: 0.001, CPU_group_0_63639ba0c12292c9677a42d0630201000000: 1, }, function_descriptor={type=PythonFunctionDescriptor, module_name=verl.single_controller.ray.base, class_name=create_colocated_worker_cls.<locals>.WorkerDict, function_name=__init__, function_hash=c9fcaae4a0634132bed0ee44930ddbab}, task_id=ffffffffffffffff119135d41f3c0a01ae1883dd01000000, task_name=2paz6NWorkerDict_0:0:WorkerDict.__init__, job_id=01000000, num_args=0, num_returns=1, max_retries=0, depth=2, attempt_number=0, actor_creation_task_spec={actor_id=119135d41f3c0a01ae1883dd01000000, max_restarts=0, max_concurrency=1, is_asyncio_actor=0, is_detached=0}, runtime_env_hash=-1775124242, eager_install=1, setup_timeout_seconds=600
Task assigned time 1970-01-01T00:00:00+00:00 worker id fc915d7501a00e73ef81f10c5b9ec92328923a7784136794e719f5b4 memory used 41320448 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 9d9fbadc43e0bc9e7407be21dd19757d66f897a1209292b05d9d0825 memory used 41336832 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 2f2bf48676361753abc6551d58e9429195afab486ab41601e6944849 memory used 41345024 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 7ee73985527711d782888c62e5d5d82ab3a80404540021d89384befe memory used 41340928 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 2025-05-04T17:13:12.729494328+00:00 worker id 35007cacb22a2ab9270518c3a772ef57ac2292cd841da293cf93474f memory used 448798720 task spec Type=ACTOR_CREATION_TASK, Language=PYTHON, Resources: {CPU: 1, }, function_descriptor={type=PythonFunctionDescriptor, module_name=verl.workers.reward.function, class_name=BatchFunctionRewardManager, function_name=__init__, function_hash=1a7763f6398e4b55b5ba9fedea414ed6}, task_id=ffffffffffffffff9a34dc5333bf4e603e04387101000000, task_name=BatchFunctionRewardManager.__init__, job_id=01000000, num_args=4, num_returns=1, max_retries=0, depth=2, attempt_number=0, actor_creation_task_spec={actor_id=9a34dc5333bf4e603e04387101000000, max_restarts=0, max_concurrency=1, is_asyncio_actor=0, is_detached=0}
Task assigned time 1970-01-01T00:00:00+00:00 worker id 84b1d19ee1292292dbf0cd223cca2b6056113572d81d49d06d86303a memory used 41312256 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 2d71ca0bcd8fdc19f38133927a911caf8b7cca9a4b84e787ea090ea4 memory used 41328640 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0
Task assigned time 1970-01-01T00:00:00+00:00 worker id 628fb177ac05b590985fa790bc236a8b104c7e7dfcf214cf700c43b0 memory used 41320448 task spec Type=NORMAL_TASK, Language=PYTHON, Resources: {}, function_descriptor={type=EmptyFunctionDescriptor}, task_id=NIL_ID, task_name=, job_id=NIL_ID, num_args=0, num_returns=0, max_retries=0, depth=0, attempt_number=0

Task should be retried? 0
[2025-05-04 19:17:37,714 I 1883226 1883226] (raylet) node_manager.cc:3057: Killing worker with task Type=ACTOR_CREATION_TASK, Language=PYTHON, Resources: {CPU_group_63639ba0c12292c9677a42d0630201000000: 1, GPU_group_0_63639ba0c12292c9677a42d0630201000000: 1, GPU_group_63639ba0c12292c9677a42d0630201000000: 1, bundle_group_0_63639ba0c12292c9677a42d0630201000000: 0.001, bundle_group_63639ba0c12292c9677a42d0630201000000: 0.001, CPU_group_0_63639ba0c12292c9677a42d0630201000000: 1, }, function_descriptor={type=PythonFunctionDescriptor, module_name=verl.single_controller.ray.base, class_name=create_colocated_worker_cls.<locals>.WorkerDict, function_name=__init__, function_hash=c9fcaae4a0634132bed0ee44930ddbab}, task_id=ffffffffffffffff119135d41f3c0a01ae1883dd01000000, task_name=2paz6NWorkerDict_0:0:WorkerDict.__init__, job_id=01000000, num_args=0, num_returns=1, max_retries=0, depth=2, attempt_number=0, actor_creation_task_spec={actor_id=119135d41f3c0a01ae1883dd01000000, max_restarts=0, max_concurrency=1, is_asyncio_actor=0, is_detached=0}, runtime_env_hash=-1775124242, eager_install=1, setup_timeout_seconds=600

Memory on the node (IP: 10.153.51.195, ID: 526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277) where the task (actor ID: 119135d41f3c0a01ae1883dd01000000, name=2paz6NWorkerDict_0:0:WorkerDict.__init__, pid=1886580, memory used=85.78GB) was running was 119.44GB / 125.60GB (0.950996), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 15629c5564e3fadc61478ea400fccad8e9ac6659227384271beb54b5) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 10.153.51.195`. To see the logs of the worker, use `ray logs worker-15629c5564e3fadc61478ea400fccad8e9ac6659227384271beb54b5*out -ip 10.153.51.195. Top 10 memory users:
PID	MEM(GB)	COMMAND
1886580	85.78	ray::WorkerDict.actor_rollout_generate_sequences
1687895	0.92	/home/wiss/liao/.vscode-server/cli/servers/Stable-ddc367ed5c8936efe395cffeec279b04ffd7db78/server/no...
1687772	0.86	/home/wiss/liao/.vscode-server/cli/servers/Stable-ddc367ed5c8936efe395cffeec279b04ffd7db78/server/no...
1882418	0.49	python3 -m verl.trainer.main_tools config=examples/config_tools.yaml data.train_files=BLINK-Benchmar...
1883367	0.49	ray::BatchFunctionRewardManager
1687787	0.48	/home/wiss/liao/.vscode-server/cli/servers/Stable-ddc367ed5c8936efe395cffeec279b04ffd7db78/server/no...
1883373	0.42	ray::BatchFunctionRewardManager
1883368	0.20	ray::Runner.run
1893097	0.19	ray::Runner.run
1893098	0.18	ray::Runner.run

Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. Set max_restarts and max_task_retries to enable retry when the task crashes due to OOM. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.
[2025-05-04 19:17:37,714 I 1883226 1883226] (raylet) node_manager.cc:1549: NodeManager::DisconnectClient, disconnect_type=4, has creation task exception = false
[2025-05-04 19:17:37,716 I 1883226 1883226] (raylet) node_manager.cc:1549: NodeManager::DisconnectClient, disconnect_type=0, has creation task exception = false
[2025-05-04 19:17:37,716 I 1883226 1883226] (raylet) node_manager.cc:1563: Ignoring client disconnect because the client has already been disconnected.
[2025-05-04 19:17:37,817 I 1883226 1883226] (raylet) local_resource_manager.cc:292: Object store memory is not idle.
[2025-05-04 19:17:38,816 I 1883226 1883226] (raylet) node_manager.cc:1549: NodeManager::DisconnectClient, disconnect_type=3, has creation task exception = false
[2025-05-04 19:17:38,817 I 1883226 1883226] (raylet) node_manager.cc:1654: Driver (pid=1882418) is disconnected. worker_id=01000000ffffffffffffffffffffffffffffffffffffffffffffffff job_id=01000000
[2025-05-04 19:17:38,819 I 1883226 1883226] (raylet) node_manager.cc:1082: The leased worker 2f42c986ad1cd9cfbffa7ff657d795fc9481e7ea1a2c40b84c354d78 is killed because the owner process 01000000ffffffffffffffffffffffffffffffffffffffffffffffff died.
[2025-05-04 19:17:38,820 I 1883226 1883226] (raylet) worker_pool.cc:719: Job 01000000 already started in worker pool.
[2025-05-04 19:17:38,820 I 1883226 1883226] (raylet) node_manager.cc:640: The leased worker  is killed because the job 01000000 finished. worker_id=2f42c986ad1cd9cfbffa7ff657d795fc9481e7ea1a2c40b84c354d78
[2025-05-04 19:17:38,820 I 1883226 1883226] (raylet) node_manager.cc:640: The leased worker  is killed because the job 01000000 finished. worker_id=893b844e6104b8bfbe7ab227e5350214387d314adeb85bf2032d74b6
[2025-05-04 19:17:38,820 I 1883226 1883226] (raylet) node_manager.cc:640: The leased worker  is killed because the job 01000000 finished. worker_id=35007cacb22a2ab9270518c3a772ef57ac2292cd841da293cf93474f
[2025-05-04 19:17:38,842 I 1883226 1883226] (raylet) node_manager.cc:1549: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = false
[2025-05-04 19:17:38,842 I 1883226 1883226] (raylet) node_manager.cc:1549: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = false
[2025-05-04 19:17:38,843 I 1883226 1883226] (raylet) node_manager.cc:1549: NodeManager::DisconnectClient, disconnect_type=1, has creation task exception = false
[2025-05-04 19:17:38,916 W 1883226 1883226] (raylet) node_manager.cc:648: Failed to send exit request to worker : RpcError: RPC Error message: Socket closed; RPC Error details: . Killing it using SIGKILL instead. worker_id=2f42c986ad1cd9cfbffa7ff657d795fc9481e7ea1a2c40b84c354d78
[2025-05-04 19:17:38,917 I 1883226 1883226] (raylet) local_resource_manager.cc:288: Object store memory is idle.
[2025-05-04 19:17:38,932 I 1883226 1883226] (raylet) main.cc:506: received SIGTERM. Existing local drain request = None
[2025-05-04 19:17:38,932 I 1883226 1883226] (raylet) main.cc:307: Raylet graceful shutdown triggered, reason = EXPECTED_TERMINATION, reason message = received SIGTERM
[2025-05-04 19:17:38,932 I 1883226 1883226] (raylet) main.cc:310: Shutting down...
[2025-05-04 19:17:38,932 I 1883226 1883226] (raylet) accessor.cc:511: Unregistering node node_id=526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277
[2025-05-04 19:17:38,934 I 1883226 1883226] (raylet) accessor.cc:524: Finished unregistering node info, status = OK node_id=526831562d82a940089ae73a9a9e35d33bc48108d3a13a0e3deff277
[2025-05-04 19:17:38,939 I 1883226 1883226] (raylet) agent_manager.cc:113: Killing agent dashboard_agent/424238335, pid 1883334.
[2025-05-04 19:17:38,949 I 1883226 1883335] (raylet) agent_manager.cc:80: Agent process with name dashboard_agent/424238335 exited, exit code 0.
[2025-05-04 19:17:38,949 I 1883226 1883226] (raylet) agent_manager.cc:113: Killing agent runtime_env_agent, pid 1883336.
[2025-05-04 19:17:38,958 I 1883226 1883337] (raylet) agent_manager.cc:80: Agent process with name runtime_env_agent exited, exit code 0.
[2025-05-04 19:17:38,958 I 1883226 1883226] (raylet) io_service_pool.cc:47: IOServicePool is stopped.
[2025-05-04 19:17:39,001 I 1883226 1883226] (raylet) stats.h:120: Stats module has shutdown.
